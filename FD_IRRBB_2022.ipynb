{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Import dữ liệu FD Balance mới vào file lưu trữ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path,getcwd\n",
    "import pickle as pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'No object named data in the file'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-63-21d006aa1f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[0mto_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimestamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2022-08-31'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m \u001b[0mfrom_date\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mselect_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CHECK_TO_DATE\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTimedelta\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1D\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m \u001b[0mlist_date_import\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfrom_date\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mto_date\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mselect_column\u001b[1;34m(self, key, column, start, stop)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m         \"\"\"\n\u001b[1;32m--> 914\u001b[1;33m         \u001b[0mtbl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_storer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    915\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtbl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"can only read_column with a table\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\io\\pytables.py\u001b[0m in \u001b[0;36mget_storer\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1484\u001b[0m         \u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1485\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgroup\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1486\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"No object named {key} in the file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1487\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1488\u001b[0m         \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_storer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'No object named data in the file'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path,getcwd\n",
    "# import pickle5 as pickle\n",
    "\n",
    "def change_type_table(file):\n",
    "    file.ACCTNO=file.ACCTNO.astype(\"uint64\")\n",
    "    file.CIFNO=file.CIFNO.astype(\"uint32\")\n",
    "    file.BRN=file.BRN.astype(\"uint16\")\n",
    "    file.STATUS=file.STATUS.astype(\"uint8\")\n",
    "    file.CDTERM=file.CDTERM.astype(\"uint16\")\n",
    "    file.CDTCOD=file.CDTCOD.astype('category')\n",
    "    file.RATE=file.RATE.astype('float32')\n",
    "    file.CURTYP=pd.Categorical(file.CURTYP, categories=['AUD','BND','CAD','CHF','CNY','CZK','DKK','EUR','FJD','GBP','HKD','IDR','INR','JPY','KHR', 'KRW', 'LAK', 'LKR', 'MMK', 'MYR', 'NOK', 'NZD', 'PHP', 'PLN', 'RUB', 'SEK', 'SGD', 'THB', 'TRY', 'TWD', 'USD', 'VND', 'XAU'])\n",
    "\n",
    "# path\n",
    "code_folder=getcwd()\n",
    "output_folder=path.join(code_folder,'Output')\n",
    "data_folder =path.join(code_folder,'Data')\n",
    "fd_save = path.join(code_folder,'fd_save')\n",
    "fd_import_file = path.join(data_folder, 'fd_files')\n",
    "# gán biến parameter\n",
    "end_date=pd.Timestamp('2021-08-31')\n",
    "start_date=pd.Timestamp('2015-10-31')\n",
    "list_bank=['L','S','B','C','R',\"F\",\"NF\"]\n",
    "list_CCY=['VND','USD','OTH']\n",
    "tw = [1,7,30,90,180,365,730,1095,1460,1825,2190]\n",
    "list_date=pd.date_range(start=start_date,end=end_date).tolist()\n",
    "\n",
    "file_data_name=path.join(data_folder,\"FD_BALANCE_30062022.h5\")\n",
    "store=pd.HDFStore(file_data_name)\n",
    "\n",
    "# gán biến to import data\n",
    "\n",
    "store.open()\n",
    "to_date=pd.Timestamp('2022-08-31')\n",
    "from_date=store.select_column(\"data\",\"CHECK_TO_DATE\").max()+pd.Timedelta(\"1D\")\n",
    "list_date_import=pd.date_range(start=from_date,end=to_date).tolist()\n",
    "\n",
    "for import_day in list_date_import[:2]:\n",
    "    print(import_day,end='\\r')\n",
    "    store.open()\n",
    "    file_name=\"CD_{}\".format(import_day.strftime(format=\"%Y_%m_%d\"))\n",
    "    try:\n",
    "        #data=pickle.load(open(path.join(fd_import_file,\"{}.pickle\".format(file_name.upper())),\"rb\"))\n",
    "        #data = pd.read_csv(path.join(fd_import_file, \"{}.csv\".format(file_name)))\n",
    "        data = pd.read_csv(r\"D:\\IRRBB 2022\\Data\\fd_files\\{}.csv\".format(file_name))\n",
    "        if data['MAT_DATE'].dtypes == np.dtype('O'):\n",
    "            data['MAT_DATE'] = pd.to_datetime(data['MAT_DATE'])\n",
    "        if data['OPEN_DATE'].dtypes == np.dtype('O'):\n",
    "            data['OPEN_DATE'] = pd.to_datetime(data['OPEN_DATE'])\n",
    "        data.rename(columns={'{}'.format(import_day):\"CURRENT_BALANCE\"},inplace=True)\n",
    "        data.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    except:\n",
    "        data=pd.read_sas(path.join(fd_import_file,\"{}.sas7bdat\".format(file_name)), encoding='iso-8859-1')\n",
    "        current_balance=\"CURRENT_BALANCE\" if \"CURRENT_BALANCE\" in data.columns else file_name.upper()\n",
    "        data.rename(columns={current_balance:\"CURRENT_BALANCE\"},inplace=True)\n",
    "    change_type_table(data)\n",
    "    data[\"CHECK_TO_DATE_1\"]=import_day\n",
    "    data[\"CHECK_FROM_DATE_1\"]=import_day\n",
    "    raw=store.select('data','CHECK_TO_DATE==\\'{}\\''.format((import_day-pd.Timedelta(\"1D\")).strftime(format=\"%Y-%m-%d\")))\n",
    "    raw=raw.merge(data,how=\"outer\",indicator=True)\n",
    "    raw.loc[raw._merge!=\"left_only\",\"CHECK_TO_DATE\"]=raw.loc[raw._merge!=\"left_only\",\"CHECK_TO_DATE_1\"]\n",
    "    raw.loc[raw._merge==\"right_only\",'CHECK_FROM_DATE']=raw.loc[raw._merge==\"right_only\",'CHECK_FROM_DATE_1']\n",
    "    raw.drop(['CHECK_FROM_DATE_1','CHECK_TO_DATE_1',\"_merge\"],axis=1,inplace=True)\n",
    "    change_type_table(raw)\n",
    "    store.remove(\"data\",'CHECK_TO_DATE==\\'{}\\''.format((import_day-pd.Timedelta(\"1D\")).strftime(format=\"%Y-%m-%d\")))\n",
    "    store.put('data', raw, format='table', data_columns=True,index=False,append=True)\n",
    "    # store.close()\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chạy Mô hình FD "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import path,getcwd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION\n",
    "def classify_term_func(x):\n",
    "    if x <1 : m=\"<1M\"\n",
    "    elif x<3 : m=\"1-3M\"\n",
    "    elif x<6 : m=\"3-6M\"\n",
    "    elif x<9 : m=\"6-9M\"\n",
    "    elif x<12: m=\"9-12M\"\n",
    "    else: m=\">12M\"\n",
    "    return m\n",
    "\n",
    "def modify_columns_name(table,level,name,axis=1):\n",
    "    if axis==0:\n",
    "        table=table.T.copy()\n",
    "    else:\n",
    "        table=table.copy()\n",
    "    table.columns=pd.MultiIndex.from_tuples([tuple(x[:level])+tuple([name])+tuple(x[level+1:]) for x in table.columns],names=table.columns.names)\n",
    "    if axis==0: table=table.T\n",
    "    return table\n",
    "\n",
    "def Calculate_for_merge_bank(table,level_of_bank=1,return_merged_bank_only=False):\n",
    "    \"\"\"\n",
    "    Tính toán cho RC, LSB, BW_excl_F_NF, BW\n",
    "    \"\"\"\n",
    "    table=table.copy()\n",
    "    L_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"L\"]]\n",
    "    S_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"S\"]]\n",
    "    B_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"B\"]]\n",
    "    R_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"R\"]]\n",
    "    C_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"C\"]]\n",
    "    F_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"F\"]]\n",
    "    NF_table=table[table.columns[table.columns.get_level_values(level_of_bank)==\"NF\"]]\n",
    "    \n",
    "    SB_table=modify_columns_name(S_table,1,\"SB\").fillna(0)\\\n",
    "    .add(modify_columns_name(B_table,1,\"SB\"),fill_value=0)\n",
    "\n",
    "    LSB_table=modify_columns_name(S_table,1,\"LSB\").fillna(0)\\\n",
    "    .add(modify_columns_name(B_table,1,\"LSB\"),fill_value=0)\\\n",
    "    .add(modify_columns_name(L_table,1,\"LSB\"),fill_value=0)\n",
    "\n",
    "    RC_table=modify_columns_name(R_table,1,\"RC\").fillna(0)\\\n",
    "    .add(modify_columns_name(C_table,1,\"RC\"),fill_value=0)\n",
    "\n",
    "    BWexcl_table=modify_columns_name(RC_table,1,\"BWexcl\").fillna(0)\\\n",
    "    .add(modify_columns_name(LSB_table,1,\"BWexcl\"),fill_value=0)\n",
    "\n",
    "    BW_table=modify_columns_name(BWexcl_table,1,\"BW\").fillna(0)\\\n",
    "    .add(modify_columns_name(F_table,1,\"BW\"),fill_value=0)\\\n",
    "    .add(modify_columns_name(NF_table,1,\"BW\"),fill_value=0)\n",
    "\n",
    "    table=pd.concat([table,RC_table,SB_table,LSB_table,BWexcl_table,BW_table],axis=1)\n",
    "    \n",
    "    columns_table=table.columns\n",
    "    if return_merged_bank_only:\n",
    "        columns_table=columns_table[columns_table.get_level_values(0).isin([\"VND\",\"USD\"]) \n",
    "                                    & columns_table.get_level_values(level_of_bank).isin([\"RC\",\"LSB\",\"BWexcl\",\"SB\"])]\n",
    "        \n",
    "    reindex=columns_table[columns_table.get_level_values(0)==\"VND\"].to_list()\\\n",
    "        +columns_table[columns_table.get_level_values(0)==\"USD\"].to_list()\\\n",
    "        +columns_table[columns_table.get_level_values(0)==\"OTHER\"].to_list()\n",
    "    \n",
    "    return table[reindex].replace(0,np.nan).copy()\n",
    "\n",
    "def Calculate_ALL_TERM(table,level_Classify_term,axis=0):\n",
    "    total_level=list(range(table.index.nlevels))\n",
    "    table=modify_columns_name(table,level_Classify_term,\"ALL_TERM\",axis=axis)\n",
    "    return table.groupby(level=total_level).sum()\n",
    "\n",
    "def handling_data(data_input,bank_input,sfs_input,list_date_input,cal_cbal=True):\n",
    "    data=data_input.copy()\n",
    "    # Classify term\n",
    "    data[\"Classify_term\"]=(data.CDTCOD.astype(str).map(lambda x : 1 if x==\"M\" else 1/30)*data.CDTERM).map(classify_term_func)\n",
    "    # quy các đồng tiền khác USD về VND, đổi tên thành \"OTHER\"\n",
    "    data[\"CURRENT_BALANCE\"]=data[[\"CURRENT_BALANCE\"]].to_numpy()*sfs_input.set_index(\"CURRENCY_CODE\").reindex(data.CURTYP).to_numpy()\n",
    "    data.CURTYP=data.CURTYP.astype(\"str\")\n",
    "    data.loc[data.CURTYP.isin([\"VND\",\"USD\"])==False,\"CURTYP\"]=\"OTHER\"\n",
    "    # update the newest CIF for account (có những acc chuyển CIF) \n",
    "    data=data.sort_values([\"ACCTNO\",\"CHECK_FROM_DATE\"]).reset_index(drop=True)\n",
    "    data.loc[data.duplicated([\"ACCTNO\"],keep=\"last\"),\"CIFNO\"]=np.nan\n",
    "    data.CIFNO.fillna(method=\"bfill\",inplace=True)\n",
    "    # merge bank\n",
    "    data=data.merge(bank_input.rename(columns={\"cif_number\":\"CIFNO\"}),how=\"left\")\n",
    "\n",
    "    if cal_cbal:\n",
    "        # thêm cột cbal từng ngày\n",
    "        data[list_date_input]=np.array([np.where((data.OPEN_DATE>i),np.nan,np.array((((data.CHECK_FROM_DATE<=i) & (data.CHECK_TO_DATE>=i))*(data.CURRENT_BALANCE)))) for i in list_date_input]).T\n",
    "        # group by theo account\n",
    "        data=data.groupby([\"ACCTNO\",\"bank\",\"CURTYP\",\"Classify_term\"],as_index=False).agg({**{\"MAT_DATE\":np.max},**{n: np.sum for n in list_date_input}},skipna=True)\n",
    "        # drop những account có cbal theo chuỗi quan sát đều bằng 0\n",
    "        data.drop(data[np.nansum(data[list_date_input],1)==0].index,inplace=True)\n",
    "        # thêm cột ngày cuối cùng có số dư > 0\n",
    "        data[\"LAST_DAY_CBAL>0\"]=[list_date_input[::-1][i.index(1)] for i in (data[list_date_input[::-1]]!=0).astype(int).values.tolist()]\n",
    "        # thêm cột số dư tại ngày cuối cùng có số dư > 0\n",
    "        data[\"CBAL_AT_LAST_DAY_CBAL>0\"]=[data.loc[i,data.loc[i,\"LAST_DAY_CBAL>0\"]] for i in data.index]\n",
    "        # thêm cột trạng thái account là rút trước hạn (pre) hay đúng hạn (on) hay không xác định/chưa rút (unidentified)\n",
    "        data[\"WD_STT\"]=((data[\"LAST_DAY_CBAL>0\"]+pd.Timedelta(\"1D\"))<data.MAT_DATE).map(lambda x: \"pre\" if x else \"on\")\n",
    "        data.loc[data[end_date]>0,\"WD_STT\"]=\"unidentified\"\n",
    "        data.WD_STT=pd.Categorical(data.WD_STT)\n",
    "    return data\n",
    "\n",
    "def bank_handle(path):\n",
    "    bank=pd.read_csv(path)\n",
    "    try:\n",
    "        bank.loc[(bank.CUSTOMER_RATING==\"41\") & (bank.bank==\"F\"),\"bank\"]=\"NF\" \n",
    "    except:\n",
    "        pass\n",
    "#         print( \"--- loi---\",link)\n",
    "    bank=bank.rename(columns={(\"cifnew\" if \"cifnew\" in bank.columns else \"cif_number\"):\"cif_number\"})[[\"cif_number\",\"bank\"]]\n",
    "    return bank.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "code_folder=getcwd()\n",
    "output_folder=path.join(code_folder,'Output')\n",
    "data_folder =path.join(code_folder,'Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gán biến parameter\n",
    "end_date=pd.Timestamp('2022-08-31') # ngày cuối cùng cả train +test model\n",
    "start_date=pd.Timestamp('2015-10-31')\n",
    "list_bank=['L','S','B','C','R',\"F\",\"NF\"]\n",
    "list_CCY=['VND','USD','OTHER']\n",
    "tw_list = ['0','1','7','30','90','180','365','730','1095','1460','1825','2190']\n",
    "classify_term=[\"<1M\",\"1-3M\",\"3-6M\",\"6-9M\",\"9-12M\",\">12M\",\"ALL_TERM\"]\n",
    "kind=[\"WD\",\"PRE\"]\n",
    "\n",
    "# tạo biến trung gian\n",
    "list_date=pd.date_range(start=start_date,end=end_date).tolist()\n",
    "multi_index=np.array([[[[[(c,b,ct,t,k) for k in kind ] for t in tw_list] for ct in classify_term] for b in list_bank] for c in list_CCY]).reshape(-1,5)\n",
    "multi_index=pd.MultiIndex.from_frame(pd.DataFrame(multi_index,columns=[\"CURTYP\",\"bank\",\"Classify_term\",\"tw\",\"Kind\"]))\n",
    "\n",
    "# Khai báo seasonal\n",
    "Solar=[pd.Timestamp(year=y,month=1,day=1)for y in range(2016,2025)]\n",
    "Lunar=[pd.to_datetime(i,dayfirst=True) for i in ['8/2/2016', '28/1/2017', '16/2/2018', '5/2/2019', '25/1/2020','12/02/2021','01/02/2022','22/01/2023',\"10/02/2024\"]]\n",
    "ss_day_t0=[x for y in [pd.date_range(Solar[i]-pd.Timedelta(\"45D\"),Lunar[i]-pd.Timedelta(\"30D\")) for i in range(len(Solar))] for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rb_usd = pd.read_csv(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Work\\CD_IRRBB\\FD_2022\\Output\\wd_ratio_310822.csv\", header = [0,1,2,3], index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "if check_rb_usd.index.dtype == np.dtype(\"O\"):\n",
    "    check_rb_usd.index = pd.to_datetime(check_rb_usd.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_rb_usd = check_rb_usd[(check_rb_usd.index.isin(ss_day_t0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "check = check_rb_usd.loc[:,(check_rb_usd.columns.get_level_values(0) == 'USD',check_rb_usd.columns.get_level_values(1) == 'RC',check_rb_usd.columns.get_level_values(3) == '730')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2015-12-11', '2015-11-17', '2015-11-18', '2015-11-19',\n",
       "               '2015-11-20', '2015-11-21', '2015-11-22', '2015-11-23',\n",
       "               '2015-11-24', '2015-11-25',\n",
       "               ...\n",
       "               '2022-01-01', '2022-12-01', '2022-01-02', '2022-12-02',\n",
       "               '2022-12-03', '2022-12-04', '2022-12-05', '2022-12-06',\n",
       "               '2022-12-07', '2022-12-08'],\n",
       "              dtype='datetime64[ns]', length=353, freq=None)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>CURTYP</th>\n",
       "      <th>USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <th>RC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIND</th>\n",
       "      <th>WD_PRE_RATIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TW</th>\n",
       "      <th>730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "CURTYP              USD\n",
       "bank                 RC\n",
       "KIND       WD_PRE_RATIO\n",
       "TW                  730\n",
       "2016-01-05          1.0"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check[(check.index == pd.Timestamp('2016-01-05'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>CURTYP</th>\n",
       "      <th colspan=\"2\" halign=\"left\">USD</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <th colspan=\"2\" halign=\"left\">RC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIND</th>\n",
       "      <th>ALL</th>\n",
       "      <th>PRE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TW</th>\n",
       "      <th>730</th>\n",
       "      <th>730</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-11-17</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-12-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-01-02</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>355 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CURTYP      USD     \n",
       "bank         RC     \n",
       "KIND        ALL  PRE\n",
       "TW          730  730\n",
       "2015-11-17  0.0  0.0\n",
       "2015-11-18  0.0  0.0\n",
       "2015-11-19  0.0  0.0\n",
       "2015-11-20  0.0  0.0\n",
       "2015-11-21  0.0  0.0\n",
       "...         ...  ...\n",
       "2021-12-29  NaN  NaN\n",
       "2021-12-30  NaN  NaN\n",
       "2021-12-31  NaN  NaN\n",
       "2022-01-01  NaN  NaN\n",
       "2022-01-02  NaN  NaN\n",
       "\n",
       "[355 rows x 2 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "bank_train = bank_handle(path.join(data_folder, 'bank_2022_07_31_train.csv'))\n",
    "bank_test = bank_handle(path.join(data_folder, 'bank_2022_08_31_train+test.csv'))\n",
    "bank=bank_train.combine_first(bank_test)\n",
    "'''check NF F\n",
    "Do bang bank bi gop NF + F = F, xin them file ben RDM de boc tach NF va F\n",
    "'''\n",
    "NFI = pd.read_excel(path.join(data_folder, 'F_NF 31082022.xlsx'))\n",
    "NF_acc = NFI[(NFI.INDICATOR_BU == 'NF')]\n",
    "list_NF = NF_acc.CPTY_ID_CORE.unique().tolist()\n",
    "bank.loc[(bank.cif_number.isin(list_NF)), 'bank'] = 'NF'\n",
    "bank.to_csv(path.join(data_folder,'final_bank_310822.csv'))\n",
    "#bank = bank_handle(path.join(data_folder,'bank_2021_10_31.pickle'))\n",
    "#bank.to_pickle(path.join(data_folder,r\"Data_final_for_2022\\bank_total_2021_10_31.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ty gia\n",
    "sfs=pd.read_excel(path.join(data_folder,'SSFXRT_MHCC_2022_08_31_train+test.xlsx'))\n",
    "sfs.columns=sfs.columns.map(lambda x:x.upper())\n",
    "sfs.loc[sfs.CURRENCY_CODE==\"USD\",\"MID_RATE\"]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "sfs.drop('UNNAMED: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "store = pd.HDFStore(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Work\\CD_IRRBB\\FD_2022\\Data\\FD_BALANCE_310822.h5\") # cbal\n",
    "store.open()\n",
    "#input xlkt\n",
    "xlkt_acc_1 = pd.read_excel(data_folder+ r\"\\Gdkt_upto_72022 - Account.xlsx\").ACCTNO.unique()\n",
    "xlkt_acc_3=store.select(\"data\",columns=[\"ACCTNO\",\"CIFNO\",\"TYPE\"]) # account xlkt\n",
    "CD_and_xlkt_acc_3=xlkt_acc_3[(xlkt_acc_3.CIFNO.isin([290445,949938,290445,132738,1599267])) | # khách hàng affiliate\n",
    "                             (xlkt_acc_3.TYPE.str.startswith(\"CD\"))].ACCTNO.unique() # account CD\n",
    "xlkt_acc=xlkt_acc_1.tolist()+CD_and_xlkt_acc_3.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xlkt\n",
    "# xlkt_acc_1=pd.read_excel(data_folder+r\"\\xlkt_31082020.xlsx\",sheet_name=\"FCRM\",usecols=[2]).ACCOUNT_NO.unique() # account FCRM rút vốn linh hoạt\n",
    "# xlkt_acc_2=pd.read_csv(data_folder+r\"\\xlkt.csv\").ACCTNO.unique() # account FCRM rút vốn linh hoạt\n",
    "# Xử lý account\n",
    "# store = pd.HDFStore(path.join(data_folder,\"FD_BALANCE.h5\")) # cbal\n",
    "# store.open()\n",
    "# xlkt_acc_3=store.select(\"data\",columns=[\"ACCTNO\",\"CIFNO\",\"TYPE\"]) # account xlkt\n",
    "# CD_and_xlkt_acc_3=xlkt_acc_3[(xlkt_acc_3.CIFNO.isin([290445,949938,290445,132738,1599267])) | # khách hàng affiliate\n",
    "#                              (xlkt_acc_3.TYPE.str.startswith(\"CD\"))].ACCTNO.unique() # account CD\n",
    "# xlkt_acc=xlkt_acc_1.tolist()+xlkt_acc_2.tolist()+CD_and_xlkt_acc_3.tolist() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lấy data từ file H5\n",
    "# data sau khi lấy xong sẽ có ngày cuối cùng trùng với ngày end lựa chọn của mô hình (chỉ cần quan tâm file H5 có ngày end ko nhỏ hơn ngày end của mô hình là được)\n",
    "#Import file dữ liệu\n",
    "# store = pd.HDFStore(r\"C:\\Users\\ngocna3\\Documents\\irrbb\\FD_2022\\Data\\FD_BALANCE_31082022.h5\") # cbal\n",
    "# store.open()\n",
    "data=store.select(\"data\",auto_close=True)\n",
    "data.loc[data.CHECK_TO_DATE == pd.Timestamp('2022-01-02'), 'CHECK_TO_DATE'] = pd.Timestamp('2022-01-03') \n",
    "data.loc[data.CHECK_TO_DATE == pd.Timestamp('2022-03-13'), 'CHECK_TO_DATE'] = pd.Timestamp('2022-03-14') \n",
    "data.loc[data.CHECK_TO_DATE == pd.Timestamp('2022-03-25'), 'CHECK_TO_DATE'] = pd.Timestamp('2022-03-26') \n",
    "data=data[(data.CHECK_FROM_DATE<=end_date) & (data.ACCTNO.isin(xlkt_acc)==False) # acc xlkt\n",
    "        & (data.TYPE!=\"FCRM106\") #ung von\n",
    "        & (data.TYPE.str.contains(\"PW\")==False) # rut von linh hoat\n",
    "        & (data.CURRENT_BALANCE > 0 )].reset_index(drop=True).sort_values(\"CHECK_FROM_DATE\")\n",
    "data=handling_data(data,bank,sfs,list_date,cal_cbal=False)\n",
    "data[\"bank\"]=data[\"bank\"].map(lambda x: \"RC\" if (x in list(\"RC\")) else (\"LSB\" if (x in list(\"LSB\")) else \"F_NF\"))\n",
    "data.loc[data.CHECK_TO_DATE>end_date,\"CHECK_TO_DATE\"]=end_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-559e9dde7375>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m '''\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# thống kê account\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mreturn_df_tw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdanhmuc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmethod_mat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"All_0\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[1;31m# ví dụ danhmuc=[\"VND\",\"RC\"]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod_mat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"_\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "'''\n",
    "code cũ: ppl tính TW\n",
    "'''\n",
    "# thống kê account\n",
    "def return_df_tw(date,table=data,danhmuc=[None,None],method_mat=\"All_0\"):\n",
    "    # ví dụ danhmuc=[\"VND\",\"RC\"]\n",
    "    tw=int(method_mat.split(\"_\")[-1])\n",
    "    method=method_mat.split(\"_\")[0]\n",
    "    c_all= (True if (\"All\" in method) else False)\n",
    "    c_mat_after = ((table.MAT_DATE>(date+pd.Timedelta(str(tw)+\"D\"))) if (\"After\" in method) else False) # account có mat-date lớn hơn posted + tw\n",
    "    c_mat_equal = ((table.MAT_DATE==(date+pd.Timedelta(str(tw)+\"D\"))) if (\"Equal\" in method) else False) # account có mat-date bằng posted + tw\n",
    "    c_mat_before = ((table.MAT_DATE<(date+pd.Timedelta(str(tw)+\"D\")))  if (\"Before\" in method) else False) # account có mat-date nhỏ hơn posted + tw\n",
    "    condi_mat= (((c_all | c_mat_after) | c_mat_equal) | c_mat_before)\n",
    "    condi_cur= (True if (danhmuc[0]==None) else (table.CURTYP==danhmuc[0]))\n",
    "    condi_bank= (True if (danhmuc[1]==None) else (table.bank==danhmuc[1]))\n",
    "    return table[ (table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & condi_cur & condi_bank & condi_mat].copy()\n",
    "\n",
    "def calculate_sum_balance(date,t,table=data,key=\"ALL\",func=np.nansum):        \n",
    "    df = table[[\"CURTYP\",\"bank\",\"CURRENT_BALANCE\"]].groupby([\"CURTYP\",\"bank\"]).agg(func)\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    df[[\"KIND\",\"TW\"]]=[key,t]\n",
    "    df.set_index([\"KIND\",\"TW\"],append=True,inplace=True)\n",
    "    return df.T\n",
    "\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[level])>0:table.loc[table.index[-int(i[level]):],i]=np.nan\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "list_tw=[30,90,180,365,730,1095, 1460, 1825, 2190]\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    df_0=return_df_tw(date,method_mat=\"All_{}\".format(0)) # danh mục FD có posted = date (ký hiệu DF0)\n",
    "    for tw in list_tw:\n",
    "        print(date.date(),tw,end=\"\\r\")\n",
    "        all_after=return_df_tw(date,table=df_0,method_mat=\"After_{}\".format(tw)) # danh mục con của DF0 (posted=date) có acc có mat-date sau ngày date+tw\n",
    "        all_after_sum=calculate_sum_balance(date,tw,table=all_after,key=\"ALL\") # tính tổng giá trị danh mục all_after\n",
    "        date_tw=date+pd.Timedelta(\"{}D\".format(tw)) # date+tw\n",
    "        all_tw=return_df_tw(date_tw,table=data,method_mat=\"All_{}\".format(tw)) # danh mục có posted=date_tw\n",
    "        pre_after_sum=calculate_sum_balance(date,tw,table=all_after[~all_after.ACCTNO.isin(all_tw.ACCTNO)],\n",
    "                                        key=\"PRE\") # tính tổng danh mục của những account trong all_after nhưng không xuất hiện trong danh mục all ngày date+tw (tức số dư đã về 0 trước đó)\n",
    "        Result_day=pd.concat([Result_day,all_after_sum,pre_after_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result=Result.append(Result_day)\n",
    "Nan_to_tw(Result)\n",
    "BWex=modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"RC\"],1,\"BWex\",axis=1)\\\n",
    ".add(modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"LSB\"],1,\"BWex\",axis=1),fill_value=0)\n",
    "Result=pd.concat([Result,BWex],axis=1).sort_index(axis=1)\n",
    "# export\n",
    "Result.to_pickle(output_folder+r\"\\Result_310822.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "code mới, tính theo bucket - phương pháp luận mới\n",
    "'''\n",
    " \n",
    "####\n",
    "def return_df_tw2(date,table=data,danhmuc=[None,None],method_mat=\"ALL_0_1\"):\n",
    "    # Tw1, Tw2 là hai giá trị chặn trong Bucket muốn xét\n",
    "    # Method = ALL => xác định balance có MAT > TW2, Method = wBetween => Xác định withdrawal between Tw1 và TW2\n",
    "    tw1=int(method_mat.split(\"_\")[1])\n",
    "    tw2=int(method_mat.split(\"_\")[-1])\n",
    "    method = method_mat.split(\"_\")[0]\n",
    "    c_mat_1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\")))\\\n",
    "               if (\"ALL\" in method) else False)  \n",
    "    #các điều kiện xác định account rút trước hạn (mat>tw2 & rút trước hạn trong bucket đang xét)\n",
    "    c_wit_cond1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\"))) if (\"wbetween\" in method) else False)\n",
    "    c_wit_1 = ((table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")) if (tw1 == 0) else table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")))\\\n",
    "               if (\"wbetween\" in method) else False)\n",
    "    c_wit_2 = ((((table.CHECK_TO_DATE )<(date+pd.Timedelta(str(tw2)+\"D\"))))  if (\"wbetween\" in method) else False) \n",
    "    #c_wit_2 = (((table.CHECK_TO_DATE + pd.Timedelta(str(1)+\"D\"))<(date+pd.Timedelta(str(tw2)+\"D\"))) if (\"wbetween\" in method) else False)  \n",
    "    c_wit_between = (c_wit_cond1 & c_wit_1 &  c_wit_2)\n",
    "    \n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & ( c_mat_1 | c_wit_between) ].copy()\n",
    "\n",
    "\n",
    "def calculate_sum_balance(date,t,table=data,key=\"ALL\",func=np.nansum):        \n",
    "    df = table[[\"CURTYP\",\"bank\",\"CURRENT_BALANCE\"]].groupby([\"CURTYP\",\"bank\"]).agg(func)\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    df[[\"KIND\",\"Bucket\"]]=[key,t]\n",
    "    df.set_index([\"KIND\",\"Bucket\"],append=True,inplace=True)\n",
    "    return df.T\n",
    "\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[level].split('-')[1].split('D')[0])>0: table.loc[table.index[-int(i[level].split('-')[1].split('D')[0]):],i]=np.nan\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "list_tw1=[0,30,90,180,365,730,1095,1460,1825]\n",
    "list_tw2=[30,90,180,365,730,1095,1460,1825,2190]\n",
    "# list_tw1=[0]\n",
    "# list_tw2=[30]\n",
    "for date in list_date[:2]:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(9):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data,method_mat=\"ALL_{}_{}\".format(list_tw1[i],list_tw2[i])) # trả về bảng có mat > date + tw2\n",
    "        all_mat_bucket_sum=calculate_sum_balance(date,t = '{}-{}'.format(list_tw1[i],list_tw2[i]),table=all_mat_bucket,key=\"ALL\") # tính tổng giá trị all_mat_bucket\n",
    "        Result_day=pd.concat([Result_day,all_mat_bucket_sum],axis=1)\n",
    "        date_tw1=date+pd.Timedelta(\"{}D\".format(list_tw1[i])) # date+tw1\n",
    "        date_tw2=date+pd.Timedelta(\"{}D\".format(list_tw2[i])) # date+tw2\n",
    "        all_tw1=return_df_tw2(date_tw1,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw1\n",
    "        all_tw2=return_df_tw2(date_tw2,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw2\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket_sum=calculate_sum_balance(date,t ='{}-{}'.format(list_tw1[i],list_tw2[i]),table=all_wit_bucket,key=\"PRE\") #tính bảng có account RTHall_mat_bucket        \n",
    "        Result_day=pd.concat([Result_day,all_wit_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "    \n",
    "\n",
    "Result=Result.sort_index(axis=1, level = [0,1,2], sort_remaining = False)\n",
    "BWex=modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"RC\"],1,\"BWex\",axis=1).add(modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"LSB\"],1,\"BWex\",axis=1),fill_value=0)\n",
    "Result=pd.concat([Result,BWex],axis=1).sort_index(axis=1, level = [0], sort_remaining = False)\n",
    "Nan_to_tw(table=Result,level=3)\n",
    "#Result.to_pickle(r\"D:\\IRRBB 2022\\output_T10_2022\\Result_31102022.pickle\") \n",
    "Result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hàm NaN của code mới\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[level].split('-')[1].split('D')[0])>0: table.loc[table.index[-int(i[level].split('-')[1].split('D')[0]):],i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_pickle(output_folder+r\"Result_31102021_v2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "Result.to_csv(\"test_send_Huong.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Xử lý file output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path,getcwd\n",
    "import numpy as np\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\ngocna3\\\\Documents\\\\My Received Files\\\\Work\\\\CD_IRRBB\\\\FD_2022\\\\Output'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "# path\n",
    "code_folder=getcwd()\n",
    "output_folder=path.join(code_folder,'Output')\n",
    "data_folder =path.join(code_folder,'Data')\n",
    "\n",
    "#Import file dữ liệu\n",
    "#Result=pd.read_pickle(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Work\\CD_IRRBB\\FD_2022\\OutputResult_31102021_v2.pickle\")\n",
    "Result = pd.read_csv(r\")\n",
    "# Khai báo seasonal\n",
    "Solar=[pd.Timestamp(year=y,month=1,day=1)for y in range(2016,2025)]\n",
    "Lunar=[pd.to_datetime(i,dayfirst=True) for i in ['8/2/2016', '28/1/2017', '16/2/2018', '5/2/2019', '25/1/2020','12/02/2021','01/02/2022','22/01/2023',\"10/02/2024\"]]\n",
    "ss_day_t0=[x for y in [pd.date_range(Solar[i]-pd.Timedelta(\"45D\"),Lunar[i]-pd.Timedelta(\"30D\")) for i in range(len(Solar))] for x in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' old code '''\n",
    "def WD_PRE_ratio_func(i,pre_t_tw_t,all_0_tw_t):\n",
    "    i_=list(i).copy()\n",
    "    i__=list(i).copy()\n",
    "    i_[2]=\"ALL\"\n",
    "    i__[2]=\"WD_PRE_RATIO\"\n",
    "    wdr_pre=(pre_t_tw_t[i]/all_0_tw_t[tuple(i_)]).fillna(0).copy()\n",
    "    #wdr_pre.iloc[-i[3]:]=np.nan\n",
    "    return pd.DataFrame(wdr_pre,columns=pd.MultiIndex.from_tuples([tuple(i__)],names=pre_t_tw_t.columns.names))\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[level])>0:table.loc[table.index[-int(i[level]):],i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' new code '''\n",
    "# verse 2\n",
    "def W_ratio(i,pre_t_tw_t,all_0_tw_t):\n",
    "    i_=list(i).copy()\n",
    "    i__=list(i).copy()\n",
    "    i_[2]=\"ALL\"\n",
    "    i__[2]=\"WD_RATIO\"\n",
    "    wdr_pre=(pre_t_tw_t[i]/all_0_tw_t[tuple(i_)]).fillna(0).copy()\n",
    "    return pd.DataFrame(wdr_pre,columns=pd.MultiIndex.from_tuples([tuple(i__)],names=pre_t_tw_t.columns.names))\n",
    "\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[level].split('-')[1].split('D')[0])>0: table.loc[table.index[-int(i[level].split('-')[1].split('D')[0]):],i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính WD ratio cho rút trước hạn\n",
    "all_0_tw_t=Result.iloc[:, (Result.columns.get_level_values(\"KIND\")=='ALL') ].copy()\n",
    "pre_t_tw_t=Result.iloc[:, (Result.columns.get_level_values(\"KIND\")=='PRE')].copy()\n",
    "wd_ratio=pd.concat([ WD_PRE_ratio_func(i,pre_t_tw_t,all_0_tw_t) for i in pre_t_tw_t.columns],axis=1)\n",
    "#wd_ratio.to_pickle(output_folder+r\"\\wd_ratio_310822_v2.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new\n",
    "wd_ratio = pd.read_excel(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Ratio_ver2(1).xlsx\", header = [0,1,2,3], index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ngocna3 edits\n",
    "def Nan_to_tw(table):\n",
    "    table.fillna(0,inplace=True)\n",
    "    for i in table.columns:\n",
    "        if int(i[3].split('-')[1].split('D')[0])>0:table.loc[table.index[-int(i[3].split('-')[1].split('D')[0]):],i]=np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>CURTYP</th>\n",
       "      <th colspan=\"8\" halign=\"left\">OTHER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">USD</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">VND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RC</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BWex</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSB</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">BWex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIND</th>\n",
       "      <th colspan=\"4\" halign=\"left\">WD_RATIO</th>\n",
       "      <th colspan=\"4\" halign=\"left\">WD_RATIO</th>\n",
       "      <th colspan=\"2\" halign=\"left\">WD_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">WD_RATIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bucket</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>...</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>270-365D</th>\n",
       "      <th>365-730D</th>\n",
       "      <th>730-1095D</th>\n",
       "      <th>1095-1460D</th>\n",
       "      <th>1460-1825D</th>\n",
       "      <th>1825-2190D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-03-05</th>\n",
       "      <td>0.107416</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107416</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027316</td>\n",
       "      <td>0.021972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-06</th>\n",
       "      <td>0.109367</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109367</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026497</td>\n",
       "      <td>0.021775</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-07</th>\n",
       "      <td>0.094899</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.094899</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030882</td>\n",
       "      <td>0.022785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-08</th>\n",
       "      <td>0.062384</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062384</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030300</td>\n",
       "      <td>0.022715</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-03-09</th>\n",
       "      <td>0.088719</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088719</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030058</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CURTYP         OTHER                                                         \\\n",
       "bank              RC                                 BWex                     \n",
       "KIND        WD_RATIO                             WD_RATIO                     \n",
       "Bucket         0-30D    30-90D 90-180D 180-270D     0-30D    30-90D 90-180D   \n",
       "2022-03-05  0.107416  0.000301     NaN      NaN  0.107416  0.000301     NaN   \n",
       "2022-03-06  0.109367  0.000312     NaN      NaN  0.109367  0.000312     NaN   \n",
       "2022-03-07  0.094899  0.000294     NaN      NaN  0.094899  0.000294     NaN   \n",
       "2022-03-08  0.062384  0.000271     NaN      NaN  0.062384  0.000271     NaN   \n",
       "2022-03-09  0.088719  0.000271     NaN      NaN  0.088719  0.000271     NaN   \n",
       "...              ...       ...     ...      ...       ...       ...     ...   \n",
       "2022-08-27       NaN       NaN     NaN      NaN       NaN       NaN     NaN   \n",
       "2022-08-28       NaN       NaN     NaN      NaN       NaN       NaN     NaN   \n",
       "2022-08-29       NaN       NaN     NaN      NaN       NaN       NaN     NaN   \n",
       "2022-08-30       NaN       NaN     NaN      NaN       NaN       NaN     NaN   \n",
       "2022-08-31       NaN       NaN     NaN      NaN       NaN       NaN     NaN   \n",
       "\n",
       "CURTYP                   USD         ...       VND                             \\\n",
       "bank                     LSB         ...      BWex                              \n",
       "KIND                WD_RATIO         ...  WD_RATIO                              \n",
       "Bucket     180-270D    0-30D 30-90D  ...     0-30D    30-90D 90-180D 180-270D   \n",
       "2022-03-05      NaN      0.0    0.0  ...  0.027316  0.021972     NaN      NaN   \n",
       "2022-03-06      NaN      0.0    0.0  ...  0.026497  0.021775     NaN      NaN   \n",
       "2022-03-07      NaN      0.0    0.0  ...  0.030882  0.022785     NaN      NaN   \n",
       "2022-03-08      NaN      0.0    0.0  ...  0.030300  0.022715     NaN      NaN   \n",
       "2022-03-09      NaN      0.0    0.0  ...  0.030058  0.021746     NaN      NaN   \n",
       "...             ...      ...    ...  ...       ...       ...     ...      ...   \n",
       "2022-08-27      NaN      NaN    NaN  ...       NaN       NaN     NaN      NaN   \n",
       "2022-08-28      NaN      NaN    NaN  ...       NaN       NaN     NaN      NaN   \n",
       "2022-08-29      NaN      NaN    NaN  ...       NaN       NaN     NaN      NaN   \n",
       "2022-08-30      NaN      NaN    NaN  ...       NaN       NaN     NaN      NaN   \n",
       "2022-08-31      NaN      NaN    NaN  ...       NaN       NaN     NaN      NaN   \n",
       "\n",
       "CURTYP                                                                   \n",
       "bank                                                                     \n",
       "KIND                                                                     \n",
       "Bucket     270-365D 365-730D 730-1095D 1095-1460D 1460-1825D 1825-2190D  \n",
       "2022-03-05      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-03-06      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-03-07      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-03-08      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-03-09      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "...             ...      ...       ...        ...        ...        ...  \n",
       "2022-08-27      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-08-28      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-08-29      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-08-30      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "2022-08-31      NaN      NaN       NaN        NaN        NaN        NaN  \n",
       "\n",
       "[180 rows x 58 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_ratio.tail(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phương pháp cắt percentile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tính percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOL while scanning string literal (<ipython-input-297-64fcef006cbd>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-297-64fcef006cbd>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    wd_ratio = pd.read_csv(r\")\u001b[0m\n\u001b[1;37m                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOL while scanning string literal\n"
     ]
    }
   ],
   "source": [
    "wd_ratio = pd.read_csv(r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_ratio= pd.read_excel(r\" \",header =[0,1,2,3], index_col =[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tập train truoc 30 ngay\n",
    "wd_ratio_train=wd_ratio.iloc[:-30].copy()\n",
    "Nan_to_tw(wd_ratio_train)\n",
    "#wd_ratio_train = wd_ratio_train.drop(2190, axis = 1, level = 3) #khi fill = np.nan thi cot 2190 nan het\n",
    "\n",
    "def calculate_percentile(good_or_bad=\"bad\",wd_ratio_train=wd_ratio_train):\n",
    "    per,st_rank= (90,-10) if good_or_bad == \"bad\" else (10,9)\n",
    "    \n",
    "    # tính bộ tỷ lệ trong các điều kiện persentile 90%\n",
    "    normal=wd_ratio_train[ (~wd_ratio_train.index.isin(ss_day_t0))].apply(lambda x:np.nanpercentile(x.iloc[-365-x.isna().sum():],per))\n",
    "    seasonal=wd_ratio_train[wd_ratio_train.index.isin(ss_day_t0)].apply(lambda x:np.nanpercentile(x,per))\n",
    "    stress=wd_ratio_train.apply(lambda x:np.sort(x[~np.isnan(x)])[st_rank])\n",
    "\n",
    "    wd_ratio_percentile=pd.concat([normal,seasonal,stress],axis=1).rename(columns={0:\"Normal\",1:\"Seasonal\",2:\"Stress\"}).reset_index()\n",
    "    wd_ratio_percentile=wd_ratio_percentile.melt(id_vars=['CURTYP','bank',\"Bucket\",\"KIND\"],value_vars=['Normal','Seasonal','Stress'],var_name=\"Time\",value_name=\"Ratio\")\\\n",
    "        .pivot_table(values=\"Ratio\",columns=['KIND',\"Bucket\"],index=['Time','CURTYP','bank'])\n",
    "    # wd_ratio_percentile=wd_ratio_percentile.applymap(lambda x:'{:.1%}'.format(x))\n",
    "    wd_ratio_percentile.reset_index(inplace=True)\n",
    "    wd_ratio_percentile=wd_ratio_percentile[(wd_ratio_percentile.CURTYP!=\"OTHER\") \n",
    "                                            & ~(wd_ratio_percentile.bank.isin([\"F_NF\"])) \n",
    "                                            & ~((wd_ratio_percentile.bank.isin([\"BWex\",\"LSB\"])) & (wd_ratio_percentile.CURTYP==\"USD\"))]\\\n",
    "    .sort_values([\"Time\",\"CURTYP\",\"bank\"],ascending=[True,False,True])\n",
    "    return wd_ratio_percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer= pd.ExcelWriter(output_folder+r\"\\wd_ratio_percentile_310822_new_method.xlsx\",engine=\"openpyxl\")#mode=\"+a\")\n",
    "calculate_percentile(\"good\").to_excel(writer,sheet_name=\"good\")\n",
    "calculate_percentile(\"bad\").to_excel(writer,sheet_name=\"bad\")\n",
    "writer.save()\n",
    "\n",
    "#calculate_percentile(\"bad\").to_pickle(output_folder+r\"\\wd_ratio_percentile_310822.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_percentile(\"bad\").to_pickle(output_folder+r\"\\wd_ratio_percentile_310822.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backtest percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path,getcwd\n",
    "import numpy as np\n",
    "\n",
    "# path\n",
    "code_folder=getcwd()\n",
    "output_folder=path.join(code_folder,'Output')\n",
    "data_folder =path.join(code_folder,'Data')\n",
    "\n",
    "#Import file dữ liệu\n",
    "Result=pd.read_excel(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Result_ver2.xlsx\", header = [0,1,2,3], index_col = [0])\n",
    "Nan_to_tw(Result)\n",
    "wd_ratio_percentile=calculate_percentile(\"bad\")\n",
    "\n",
    "# Khai báo seasonal\n",
    "Solar=[pd.Timestamp(year=y,month=1,day=1)for y in range(2016,2025)]\n",
    "Lunar=[pd.to_datetime(i,dayfirst=True) for i in ['8/2/2016', '28/1/2017', '16/2/2018', '5/2/2019', '25/1/2020','12/02/2021','01/02/2022','22/01/2023',\"10/02/2024\"]]\n",
    "ss_day_t0=[x for y in [pd.date_range(Solar[i]-pd.Timedelta(\"45D\"),Lunar[i]-pd.Timedelta(\"30D\")) for i in range(len(Solar))] for x in y]\n",
    "\n",
    "#Import file dữ liệu\n",
    "day_bt_list=[30,90,180,365,730,1095]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' code cũ - dùng cho tw '''\n",
    "def cut_off_obs(df,day_bt,condi,num_test_obs): # lọc quan sát theo điều kiện\n",
    "    df2=df.iloc[:-day_bt].copy()\n",
    "    if condi.lower()==\"normal\":\n",
    "        df2=df2[~df2.index.isin(ss_day_t0)].iloc[-365-int(num_test_obs):]\n",
    "    elif condi.lower()==\"seasonal\":\n",
    "        df2=df2[df2.index.isin(ss_day_t0)]\n",
    "    else: #stress\n",
    "        df2=df2\n",
    "    return df2\n",
    "\n",
    "def calculate_backtest(report,wd_percentile_raw,b,c,condi,bt,num_test_obs):\n",
    "    df=report.iloc[:,(report.columns.get_level_values(\"CURTYP\")==c) & (report.columns.get_level_values(\"bank\")==b) \n",
    "                     & (report.columns.get_level_values(\"Bucket\")==bt)].copy().sort_index(level=[\"KIND\"],axis=1)\n",
    "        \n",
    "    df.columns=[\"CB0\",\"CB_T\"]\n",
    "    wd_ratio=wd_percentile_raw.loc[(wd_percentile_raw.Time==condi.capitalize())\n",
    "                     &(wd_percentile_raw.CURTYP==c)\n",
    "                     &(wd_percentile_raw.bank==b),wd_percentile_raw.columns.get_level_values(\"Bucket\")==bt].values[0][0]\n",
    "    df[\"WD_Estimate\"]=wd_ratio*df[\"CB0\"]\n",
    "    df[\"Violation\"]=(df[\"CB_T\"]>df[\"WD_Estimate\"]).astype(int)\n",
    "    df[\"Balance_violation\"]=df[\"Violation\"]*(df[\"CB_T\"]-df[\"WD_Estimate\"])\n",
    "    df[\"%Balance_violation\"]=df[\"Balance_violation\"]/df[\"CB0\"]\n",
    "    func={\"Violation\":np.nansum,\"Balance_violation\":np.nanmean,\"%Balance_violation\":[np.nanmax,np.nanmean]}\n",
    "    df[[\"Bank\",\"CCY\",\"Condition\",\"Bucket\"]]=[b,c,condi,bt]\n",
    "    df[\"CB_T_in_SS\"]=df[\"CB_T\"]*df.index.map(lambda x: np.nan if x not in ss_day_t0 else 1)\n",
    "    df_cut_off=cut_off_obs(df=df,day_bt=bt,condi=condi,num_test_obs=num_test_obs)\n",
    "    df_month=df_cut_off.reset_index().groupby(pd.Grouper(key='index',freq=\"M\")).agg(func).reset_index()\n",
    "    df_month.columns=df_month.columns.map(lambda x: \"_\".join(x))\n",
    "    df_month[[\"Bank\",\"CCY\",\"Condition\",\"Bucket\"]]=[b,c,condi,bt]\n",
    "    return df.iloc[:-bt].reset_index(),df_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 2 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-230-f9a52a393de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mbt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mday_bt_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mcondition\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"Stress\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Seasonal\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Normal\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;31m#\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m             \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf_month\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcalculate_backtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mResult\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mwd_percentile_raw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwd_ratio_percentile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcondi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcondition\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mbt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnum_test_obs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnum_test_obs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m             \u001b[0mbacktest_result_day\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbacktest_result_day\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m             \u001b[0mbacktest_result_month\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbacktest_result_month\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_month\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-229-b6d06ac30a0a>\u001b[0m in \u001b[0;36mcalculate_backtest\u001b[1;34m(report, wd_percentile_raw, b, c, condi, bt, num_test_obs)\u001b[0m\n\u001b[0;32m     13\u001b[0m                      & (report.columns.get_level_values(\"Bucket\")==bt)].copy().sort_index(level=[\"KIND\"],axis=1)\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"CB0\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"CB_T\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     wd_ratio=wd_percentile_raw.loc[(wd_percentile_raw.Time==condi.capitalize())\n\u001b[0;32m     17\u001b[0m                      \u001b[1;33m&\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwd_percentile_raw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCURTYP\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[1;34m(self, name, value)\u001b[0m\n\u001b[0;32m   5476\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5477\u001b[0m             \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5479\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5480\u001b[0m             \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.properties.AxisProperty.__set__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_set_axis\u001b[1;34m(self, axis, labels)\u001b[0m\n\u001b[0;32m    668\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py\u001b[0m in \u001b[0;36mset_axis\u001b[1;34m(self, axis, new_labels)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_len\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mold_len\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 220\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    221\u001b[0m                 \u001b[1;34mf\"Length mismatch: Expected axis has {old_len} elements, new \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m                 \u001b[1;34mf\"values have {new_len} elements\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 2 elements"
     ]
    }
   ],
   "source": [
    "''' code cũ '''\n",
    "# BACKTEST\n",
    "num_test_obs=30\n",
    "backtest_result_day=backtest_result_month=pd.DataFrame()\n",
    "for b,c in  [(\"RC\",\"VND\"),(\"RC\",\"USD\"),(\"LSB\",\"VND\"),(\"BWex\",\"VND\")]:\n",
    "    for bt in day_bt_list:\n",
    "        for condition in [\"Stress\",\"Seasonal\",\"Normal\"]:#\n",
    "            df,df_month=calculate_backtest(report=Result,wd_percentile_raw=wd_ratio_percentile,b=b,c=c,condi=condition,bt=bt,num_test_obs=num_test_obs)\n",
    "            backtest_result_day=backtest_result_day.append(df)\n",
    "            backtest_result_month=backtest_result_month.append(df_month)\n",
    "\n",
    "backtest_result_day_CB_T=backtest_result_day.drop_duplicates([\"index\",\"Bank\",\"CCY\",\"Bucket\"]).copy().drop([\"WD_Estimate\",'Violation','Balance_violation','%Balance_violation',\"CB0\"],axis=1)\n",
    "backtest_result_day_CB_T1=backtest_result_day_CB_T.rename(columns={\"CB_T\":\"WD_Estimate\"}).drop(\"CB_T_in_SS\",axis=1)\n",
    "backtest_result_day_CB_T1[\"Condition\"]=\"Lượng rút trước hạn\"\n",
    "backtest_result_day_CB_T2=backtest_result_day_CB_T.rename(columns={\"CB_T_in_SS\":\"WD_Estimate\"}).drop(\"CB_T\",axis=1)\n",
    "backtest_result_day_CB_T2[\"Condition\"]=\"Lượng rút trước hạn mùa vụ\"\n",
    "backtest_result_day=backtest_result_day.append(backtest_result_day_CB_T1).append(backtest_result_day_CB_T2)\n",
    "backtest_result_day.WD_Estimate.replace(0,np.nan,inplace=True)\n",
    "backtest_result_day=backtest_result_day[backtest_result_day.WD_Estimate.notna()]\n",
    "backtest_result_day=backtest_result_day.drop(backtest_result_day.columns[backtest_result_day.isna().any(0)],axis=1)            \n",
    "\n",
    "with pd.ExcelWriter(output_folder+r\"\\Plot_Backtest_FD_IRRBB_310822_new_method.xlsx\",engine='openpyxl') as writer:\n",
    "    backtest_result_day.to_excel(writer,sheet_name=\"BACKTEST DAY\",index=False)\n",
    "    backtest_result_month.to_excel(writer,sheet_name=\"BACKTEST MONTH\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' code mới - dùng cho bucket '''\n",
    "num_test_obs=92\n",
    "\n",
    "def cut_off_obs(df,day_bt,condi,num_test_obs): # lọc quan sát theo điều kiện\n",
    "    df2=df.iloc[:-(day_bt)].copy()\n",
    "    if condi.lower()==\"normal\":\n",
    "        df2=df2[~df2.index.isin(ss_day_t0)].iloc[-365-int(num_test_obs):]\n",
    "    elif condi.lower()==\"seasonal\":\n",
    "        df2=df2[df2.index.isin(ss_day_t0)]\n",
    "    else: #stress\n",
    "        df2=df2\n",
    "    return df2\n",
    "\n",
    "def calculate_backtest(report,wd_percentile_raw,b,c,condi,bt,num_test_obs):\n",
    "    df=report.iloc[:,(report.columns.get_level_values(\"CURTYP\")==c) & (report.columns.get_level_values(\"bank\")==b) \n",
    "                     & (report.columns.get_level_values(\"Bucket\")==bt)].copy().sort_index(level=[\"KIND\"],axis=1)\n",
    "    df.columns=[\"CB0\",\"CB_T\"]\n",
    "    wd_ratio=wd_percentile_raw.loc[(wd_percentile_raw.Time==condi.capitalize())\n",
    "                     &(wd_percentile_raw.CURTYP==c)\n",
    "                     &(wd_percentile_raw.bank==b),wd_percentile_raw.columns.get_level_values(\"Bucket\")==bt].values[0][0]\n",
    "    df[\"WD_Estimate\"]=wd_ratio*df[\"CB0\"]\n",
    "    df[\"Violation\"]=(df[\"CB_T\"]>df[\"WD_Estimate\"]).astype(int)\n",
    "    df[\"Balance_violation\"]=df[\"Violation\"]*(df[\"CB_T\"]-df[\"WD_Estimate\"])\n",
    "    df[\"%Balance_violation\"]=df[\"Balance_violation\"]/df[\"CB0\"]\n",
    "    func={\"Violation\":np.nansum,\"Balance_violation\":np.nanmean,\"%Balance_violation\":[np.nanmax,np.nanmean]}\n",
    "    df[[\"Bank\",\"CCY\",\"Condition\",\"Bucket\"]]=[b,c,condi,bt]\n",
    "    df[\"CB_T_in_SS\"]=df[\"CB_T\"]*df.index.map(lambda x: np.nan if x not in ss_day_t0 else 1)\n",
    "    df_cut_off=cut_off_obs(df=df,day_bt=int(bt.split('-')[1].split('D')[0]),condi=condi,num_test_obs=num_test_obs)\n",
    "    df_month=df_cut_off.reset_index().groupby(pd.Grouper(key='index',freq=\"M\")).agg(func).reset_index()\n",
    "    df_month.columns=df_month.columns.map(lambda x: \"_\".join(x))\n",
    "    df_month[[\"Bank\",\"CCY\",\"Condition\",\"Bucket\"]]=[b,c,condi,bt]\n",
    "    return df.iloc[:-(int(bt.split('-')[1].split('D')[0]))].reset_index(),df_month\n",
    "    #return df.reset_index(),df_month\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BACKTEST\n",
    "num_test_obs=30\n",
    "backtest_result_day=pd.DataFrame()\n",
    "backtest_result_month=pd.DataFrame()\n",
    "for b,c in  [(\"RC\",\"VND\"),(\"RC\",\"USD\"),(\"LSB\",\"VND\"),(\"BWex\",\"VND\")]:\n",
    "    for bt in ['0-30','30-90','90-180','180-365','365-730','730-1095']:\n",
    "        for condition in [\"Stress\",\"Seasonal\",\"Normal\"]:#\n",
    "            df,df_month=calculate_backtest(report=Result,wd_percentile_raw=wd_ratio_percentile,b=b,c=c,condi=condition,bt=bt,num_test_obs=num_test_obs)\n",
    "            backtest_result_day=backtest_result_day.append(df)\n",
    "            backtest_result_month=backtest_result_month.append(df_month)\n",
    "\n",
    "backtest_result_day_CB_T=backtest_result_day.drop_duplicates([\"index\",\"Bank\",\"CCY\",\"Bucket\"]).copy().drop([\"WD_Estimate\",'Violation','Balance_violation','%Balance_violation',\"CB0\"],axis=1)\n",
    "backtest_result_day_CB_T1=backtest_result_day_CB_T.rename(columns={\"CB_T\":\"WD_Estimate\"}).drop(\"CB_T_in_SS\",axis=1)\n",
    "backtest_result_day_CB_T1[\"Condition\"]=\"Lượng rút trước hạn\"\n",
    "backtest_result_day_CB_T2=backtest_result_day_CB_T.rename(columns={\"CB_T_in_SS\":\"WD_Estimate\"}).drop(\"CB_T\",axis=1)\n",
    "backtest_result_day_CB_T2[\"Condition\"]=\"Lượng rút trước hạn mùa vụ\"\n",
    "backtest_result_day=backtest_result_day.append(backtest_result_day_CB_T1).append(backtest_result_day_CB_T2)\n",
    "backtest_result_day.WD_Estimate.replace(0,np.nan,inplace=True)\n",
    "backtest_result_day=backtest_result_day[backtest_result_day.WD_Estimate.notna()]\n",
    "backtest_result_day=backtest_result_day.drop(backtest_result_day.columns[backtest_result_day.isna().any(0)],axis=1)            \n",
    "\n",
    "with pd.ExcelWriter(r\"D:\\IRRBB 2022\\output_T10_2022\\Backtest_FD_IRRBB_10_2022_thử lại lần 7.xlsx\",engine='openpyxl') as writer:\n",
    "    backtest_result_day.to_excel(writer,sheet_name=\"BACKTEST DAY\",index=False)\n",
    "    backtest_result_month.to_excel(writer,sheet_name=\"BACKTEST MONTH\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hồi quy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os import path,getcwd\n",
    "import os\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "import warnings\n",
    "# import ast\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "%matplotlib inline\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Khai báo biến"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "code_folder=getcwd()\n",
    "output_folder=path.join(code_folder,'Output')\n",
    "data_folder =path.join(code_folder,'Data')\n",
    "\n",
    "# Khai báo seasonal\n",
    "Solar=[pd.Timestamp(year=y,month=1,day=1)for y in range(2016,2025)]\n",
    "Lunar=[pd.to_datetime(i,dayfirst=True) for i in ['8/2/2016', '28/1/2017', '16/2/2018', '5/2/2019', '25/1/2020','12/02/2021','01/02/2022','22/01/2023',\"10/02/2024\"]]\n",
    "ss_day_t0=[x for y in [pd.date_range(Solar[i]-pd.Timedelta(\"45D\"),Lunar[i]-pd.Timedelta(\"30D\")) for i in range(len(Solar))] for x in y]\n",
    "st_msb=pd.date_range(\"2016-07-01\",\"2016-10-12\")\n",
    "\n",
    "# kết quả percentile ==> tạo kết quả mix\n",
    "#per=pd.read_pickle(output_folder+r\"\\Outputket_qua_ver2_Huong_send_241022.pickle\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biến ngày"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_day_reg=pd.Timestamp(\"2018-07-02\") # Ngày đầu tiên chạy hồi quy\n",
    "end_day_reg=pd.Timestamp(\"2022-08-31\")\n",
    "end_day_reg_train=pd.Timestamp(\"2022-07-31\")\n",
    "#số ngày giai đoạn test\n",
    "test_size=int((end_day_reg-end_day_reg_train)/pd.Timedelta(\"1D\"))\n",
    "\n",
    "#covid 2020\n",
    "covid_20 = pd.date_range(pd.Timestamp(\"2020-02-14\"),pd.Timestamp(\"2020-07-01\")).to_list()\n",
    "covid_21 = pd.date_range(pd.Timestamp(\"2021-07-09\"),pd.Timestamp(\"2021-10-11\")).to_list()\n",
    "covid = covid_20 + covid_21\n",
    "\n",
    "# Khai báo seasonal\n",
    "Solar=[pd.Timestamp(year=y,month=1,day=1)for y in range(2016,2025)]\n",
    "Lunar=[pd.to_datetime(i,dayfirst=True) for i in ['8/2/2016', '28/1/2017', '16/2/2018', '5/2/2019', '25/1/2020','12/02/2021','01/02/2022','22/01/2023',\"10/02/2024\"]]\n",
    "ss_day_t0=[x for y in [pd.date_range(Solar[i]-pd.Timedelta(\"45D\"),Lunar[i]-pd.Timedelta(\"30D\")) for i in range(len(Solar))] for x in y]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biến phụ thuộc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "Withdraw_Ratio = wd_ratio.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>CURTYP</th>\n",
       "      <th colspan=\"8\" halign=\"left\">OTHER</th>\n",
       "      <th colspan=\"2\" halign=\"left\">USD</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">VND</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bank</th>\n",
       "      <th colspan=\"4\" halign=\"left\">RC</th>\n",
       "      <th colspan=\"4\" halign=\"left\">BWex</th>\n",
       "      <th colspan=\"2\" halign=\"left\">LSB</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">BWex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KIND</th>\n",
       "      <th colspan=\"4\" halign=\"left\">WD_RATIO</th>\n",
       "      <th colspan=\"4\" halign=\"left\">WD_RATIO</th>\n",
       "      <th colspan=\"2\" halign=\"left\">WD_RATIO</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">WD_RATIO</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bucket</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>...</th>\n",
       "      <th>0-30D</th>\n",
       "      <th>30-90D</th>\n",
       "      <th>90-180D</th>\n",
       "      <th>180-270D</th>\n",
       "      <th>270-365D</th>\n",
       "      <th>365-730D</th>\n",
       "      <th>730-1095D</th>\n",
       "      <th>1095-1460D</th>\n",
       "      <th>1460-1825D</th>\n",
       "      <th>1825-2190D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-10-31</th>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.017176</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017849</td>\n",
       "      <td>0.012629</td>\n",
       "      <td>0.027391</td>\n",
       "      <td>0.027198</td>\n",
       "      <td>0.040842</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-01</th>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008545</td>\n",
       "      <td>0.017193</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018198</td>\n",
       "      <td>0.012420</td>\n",
       "      <td>0.027483</td>\n",
       "      <td>0.027044</td>\n",
       "      <td>0.043161</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-02</th>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.017034</td>\n",
       "      <td>0.184745</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018068</td>\n",
       "      <td>0.011886</td>\n",
       "      <td>0.028124</td>\n",
       "      <td>0.027009</td>\n",
       "      <td>0.041134</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-03</th>\n",
       "      <td>0.008958</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008958</td>\n",
       "      <td>0.017372</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018516</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>0.028000</td>\n",
       "      <td>0.026968</td>\n",
       "      <td>0.039527</td>\n",
       "      <td>0.007354</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-11-04</th>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.007537</td>\n",
       "      <td>0.017172</td>\n",
       "      <td>0.178573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018152</td>\n",
       "      <td>0.011689</td>\n",
       "      <td>0.027738</td>\n",
       "      <td>0.027196</td>\n",
       "      <td>0.038515</td>\n",
       "      <td>0.007364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2497 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "CURTYP         OTHER                                                   \\\n",
       "bank              RC                                   BWex             \n",
       "KIND        WD_RATIO                               WD_RATIO             \n",
       "Bucket         0-30D    30-90D   90-180D 180-270D     0-30D    30-90D   \n",
       "2015-10-31  0.008545  0.017176  0.184745      0.0  0.008545  0.017176   \n",
       "2015-11-01  0.008545  0.017193  0.184745      0.0  0.008545  0.017193   \n",
       "2015-11-02  0.008870  0.017034  0.184745      0.0  0.008870  0.017034   \n",
       "2015-11-03  0.008958  0.017372  0.178573      0.0  0.008958  0.017372   \n",
       "2015-11-04  0.007537  0.017172  0.178573      0.0  0.007537  0.017172   \n",
       "...              ...       ...       ...      ...       ...       ...   \n",
       "2022-08-27       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "2022-08-28       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "2022-08-29       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "2022-08-30       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "2022-08-31       NaN       NaN       NaN      NaN       NaN       NaN   \n",
       "\n",
       "CURTYP                             USD         ...       VND            \\\n",
       "bank                               LSB         ...      BWex             \n",
       "KIND                          WD_RATIO         ...  WD_RATIO             \n",
       "Bucket       90-180D 180-270D    0-30D 30-90D  ...     0-30D    30-90D   \n",
       "2015-10-31  0.184745      0.0      0.0    1.0  ...  0.017849  0.012629   \n",
       "2015-11-01  0.184745      0.0      0.0    1.0  ...  0.018198  0.012420   \n",
       "2015-11-02  0.184745      0.0      0.0    1.0  ...  0.018068  0.011886   \n",
       "2015-11-03  0.178573      0.0      0.0    1.0  ...  0.018516  0.011718   \n",
       "2015-11-04  0.178573      0.0      0.0    1.0  ...  0.018152  0.011689   \n",
       "...              ...      ...      ...    ...  ...       ...       ...   \n",
       "2022-08-27       NaN      NaN      NaN    NaN  ...       NaN       NaN   \n",
       "2022-08-28       NaN      NaN      NaN    NaN  ...       NaN       NaN   \n",
       "2022-08-29       NaN      NaN      NaN    NaN  ...       NaN       NaN   \n",
       "2022-08-30       NaN      NaN      NaN    NaN  ...       NaN       NaN   \n",
       "2022-08-31       NaN      NaN      NaN    NaN  ...       NaN       NaN   \n",
       "\n",
       "CURTYP                                                                   \\\n",
       "bank                                                                      \n",
       "KIND                                                                      \n",
       "Bucket       90-180D  180-270D  270-365D  365-730D 730-1095D 1095-1460D   \n",
       "2015-10-31  0.027391  0.027198  0.040842  0.007360  0.000594        0.0   \n",
       "2015-11-01  0.027483  0.027044  0.043161  0.007360  0.000594        0.0   \n",
       "2015-11-02  0.028124  0.027009  0.041134  0.007330  0.000557        0.0   \n",
       "2015-11-03  0.028000  0.026968  0.039527  0.007354  0.000000        0.0   \n",
       "2015-11-04  0.027738  0.027196  0.038515  0.007364  0.000000        0.0   \n",
       "...              ...       ...       ...       ...       ...        ...   \n",
       "2022-08-27       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2022-08-28       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2022-08-29       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2022-08-30       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2022-08-31       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "CURTYP                            \n",
       "bank                              \n",
       "KIND                              \n",
       "Bucket     1460-1825D 1825-2190D  \n",
       "2015-10-31        0.0        0.0  \n",
       "2015-11-01        0.0        0.0  \n",
       "2015-11-02        0.0        0.0  \n",
       "2015-11-03        0.0        0.0  \n",
       "2015-11-04        0.0        0.0  \n",
       "...               ...        ...  \n",
       "2022-08-27        NaN        NaN  \n",
       "2022-08-28        NaN        NaN  \n",
       "2022-08-29        NaN        NaN  \n",
       "2022-08-30        NaN        NaN  \n",
       "2022-08-31        NaN        NaN  \n",
       "\n",
       "[2497 rows x 58 columns]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Withdraw_Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biến tỷ lệ rút (biến phụ thuộc)\n",
    "Withdraw_Ratio=pd.read_excel(r\"C:\\Users\\ngocna3\\Documents\\My Received Files\\Ratio_final.xlsx\", header = [0,1,2,3], index_col = [0])\n",
    "wd_reg=Withdraw_Ratio.loc[(Withdraw_Ratio.index>=start_day_reg) & (Withdraw_Ratio.index<=end_day_reg),\n",
    "((Withdraw_Ratio.columns.get_level_values(\"CURTYP\")==\"VND\") & (Withdraw_Ratio.columns.get_level_values(\"bank\").isin([\"RC\"]))) ]\n",
    "#wd_reg.columns=[\"{}_{}_WD_{}\".format(i[0],i[1],i[3]) for i in wd_reg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg.columns = [\"{}_{}_WD_{}\".format(i[0],i[1], i[3]) for i in wd_reg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VND_RC_WD_0-30</th>\n",
       "      <th>VND_RC_WD_30-90</th>\n",
       "      <th>VND_RC_WD_90-180</th>\n",
       "      <th>VND_RC_WD_180-365</th>\n",
       "      <th>VND_RC_WD_365-730</th>\n",
       "      <th>VND_RC_WD_730-1095</th>\n",
       "      <th>VND_RC_WD_1095-1460</th>\n",
       "      <th>VND_RC_WD_1825-2190</th>\n",
       "      <th>VND_RC_WD_1460-1825</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>0.015120</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04</th>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            VND_RC_WD_0-30  VND_RC_WD_30-90  VND_RC_WD_90-180  \\\n",
       "2018-07-02        0.015092         0.006141          0.009348   \n",
       "2018-07-03        0.015120         0.006373          0.009227   \n",
       "2018-07-04        0.016331         0.006419          0.008904   \n",
       "2018-07-05        0.015359         0.006518          0.008632   \n",
       "2018-07-06        0.016748         0.006723          0.008750   \n",
       "...                    ...              ...               ...   \n",
       "2022-08-27             NaN              NaN               NaN   \n",
       "2022-08-28             NaN              NaN               NaN   \n",
       "2022-08-29             NaN              NaN               NaN   \n",
       "2022-08-30             NaN              NaN               NaN   \n",
       "2022-08-31             NaN              NaN               NaN   \n",
       "\n",
       "            VND_RC_WD_180-365  VND_RC_WD_365-730  VND_RC_WD_730-1095  \\\n",
       "2018-07-02           0.009990           0.003566                 0.0   \n",
       "2018-07-03           0.010016           0.003857                 0.0   \n",
       "2018-07-04           0.009834           0.003385                 0.0   \n",
       "2018-07-05           0.009862           0.003706                 0.0   \n",
       "2018-07-06           0.011761           0.002607                 0.0   \n",
       "...                       ...                ...                 ...   \n",
       "2022-08-27                NaN                NaN                 NaN   \n",
       "2022-08-28                NaN                NaN                 NaN   \n",
       "2022-08-29                NaN                NaN                 NaN   \n",
       "2022-08-30                NaN                NaN                 NaN   \n",
       "2022-08-31                NaN                NaN                 NaN   \n",
       "\n",
       "            VND_RC_WD_1095-1460  VND_RC_WD_1825-2190  VND_RC_WD_1460-1825  \n",
       "2018-07-02                  0.0                  NaN                  NaN  \n",
       "2018-07-03                  0.0                  NaN                  NaN  \n",
       "2018-07-04                  0.0                  NaN                  NaN  \n",
       "2018-07-05                  0.0                  NaN                  NaN  \n",
       "2018-07-06                  0.0                  NaN                  NaN  \n",
       "...                         ...                  ...                  ...  \n",
       "2022-08-27                  NaN                  NaN                  NaN  \n",
       "2022-08-28                  NaN                  NaN                  NaN  \n",
       "2022-08-29                  NaN                  NaN                  NaN  \n",
       "2022-08-30                  NaN                  NaN                  NaN  \n",
       "2022-08-31                  NaN                  NaN                  NaN  \n",
       "\n",
       "[1522 rows x 9 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg_use.VND_RC_WD_1095.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biến lãi suất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_num (df, col_list):\n",
    "    for i in col_list:\n",
    "        if df[i].dtypes == np.dtype(\"O\"):\n",
    "            df[i] = pd.to_numeric(df[i])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "scrolled": true,
    "tags": [],
    "toc-hr-collapsed": true
   },
   "outputs": [],
   "source": [
    "#```python\n",
    "# Xử lý dữ liệu thô lãi suất : file IR Survey.xlsx\n",
    "st_date=\"2018-07-02\"\n",
    "end_date=\"2022-08-31\"\n",
    "# XỬ LÝ IR\n",
    "IR=pd.read_excel(path.join(data_folder,\"IR Survey_upto_310822.xlsx\"),sheet_name=\"RAW\")\n",
    "# drop duplicated\n",
    "IR_hanlded=pd.DataFrame()\n",
    "for i in IR.BANK.unique():\n",
    "    IR_bank=IR[IR.BANK==i].copy().ffill().drop_duplicates(IR.columns[:-1])\n",
    "    IR_bank.loc[IR_bank.Date.duplicated(),\"Date\"]=IR_bank.loc[IR_bank.Date.duplicated(),\"Report_Date\"]\n",
    "    IR_hanlded=IR_hanlded.append(IR_bank)\n",
    "IR_hanlded['Date'] = pd.to_datetime(IR_hanlded['Date'], errors = 'coerce')\n",
    "# pivot_table to fill NaN\n",
    "IR=IR_hanlded.pivot_table(values=IR_hanlded.columns[5:-1],columns=\"BANK\",index=\"Date\").reorder_levels([1,0],axis=1).sort_index(axis=1)\n",
    "IR=IR.reindex(pd.date_range(IR.index.min(),IR.index.max())).ffill().reindex(pd.date_range(st_date,end_date)).dropna(how=\"all\").reset_index()\n",
    "# Melt table\n",
    "IR=IR.melt(\"index\",var_name=[\"Bank\",\"Term\"],value_name=\"rate\").pivot_table(\"rate\",[\"index\",\"Bank\"],\"Term\")\n",
    "# Interpolate missing value (tpbank 15M)\n",
    "IR.columns=IR.columns.map(lambda x:int(x[:-1]))\n",
    "IR=IR.sort_index(axis=1).reset_index().rename(columns={\"index\":\"day\"})\n",
    "# set group bank \n",
    "G1=[\"ACB\",\"EXIMBANK\",\"MB\",\"SACOMBANK\",\"TECHCOMBANK\",\"VIB\"]\n",
    "G2=[\"LIENVIET BANK\",\"DONG A BANK\",\"PVCOMBANK\",\"SCB\",\"SHB\",\"SEABANK\",\"TP BANK\",\"VP BANK\"]\n",
    "IR[\"group\"]=IR.Bank.map(lambda x: \"G1\" if x.upper() in G1 else (\"G2\" if x.upper() in G2 else \"MSB\"))\n",
    "# groupby by Date and Group\n",
    "IR_groupby_term=IR.groupby([\"day\",\"group\"],as_index=False).agg(np.nanmean)\n",
    "IR_groupby_term.columns=IR_groupby_term.columns.map(lambda x: x if type(x) == str else str(x)+\"M\")\n",
    "IR_groupby_term.to_pickle(path.join(data_folder,\"IR_groupby_term.pickle\"))\n",
    "#```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bien lai suat\n",
    "IR_groupby_term=pd.read_pickle(data_folder+r\"\\IR_groupby_term.pickle\")\n",
    "\n",
    "# Group Term LS\n",
    "IR_groupby_term[\"Short_Term\"]=(IR_groupby_term[\"1M\"]+IR_groupby_term[\"3M\"])/2\n",
    "IR_groupby_term[\"Medium_Term\"]=(IR_groupby_term[\"6M\"]+IR_groupby_term[\"9M\"])/2\n",
    "IR_groupby_term[\"Long_Term\"]=(IR_groupby_term[\"12M\"]+IR_groupby_term[\"13M\"]+IR_groupby_term[\"15M\"]+\n",
    "                              IR_groupby_term[\"18M\"]+IR_groupby_term[\"24M\"]+IR_groupby_term[\"36M\"])/6\n",
    "\n",
    "G1=IR_groupby_term[IR_groupby_term.group==\"G1\"].set_index(\"day\").drop(\"group\",axis=1)\n",
    "G2=IR_groupby_term[IR_groupby_term.group==\"G2\"].set_index(\"day\").drop(\"group\",axis=1)\n",
    "MSB=IR_groupby_term[IR_groupby_term.group==\"MSB\"].set_index(\"day\").drop(\"group\",axis=1)\n",
    "\n",
    "MSB_G1=MSB-G1\n",
    "MSB_G2=MSB-G2\n",
    "MSB.columns=\"MSB_\"+MSB.columns\n",
    "MSB_G1.columns=\"MSB_G1_\"+MSB_G1.columns\n",
    "MSB_G2.columns=\"MSB_G2_\"+MSB_G2.columns\n",
    "\n",
    "IR_variable=pd.concat([MSB,MSB_G1,MSB_G2],axis=1)\n",
    "IR_variable.index.name=\"Date\"\n",
    "IR_variable=IR_variable.reindex(wd_reg.index).ffill()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### biến dummy condition period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biến dummy condition period\n",
    "dummy_period_variables=pd.DataFrame(columns=[\"ss_dummy\",\"covid_dummy\"],index=wd_reg.index)\n",
    "dummy_period_variables[\"ss_dummy\"]=dummy_period_variables.index.isin(ss_day_t0).astype(int)\n",
    "dummy_period_variables[\"covid_dummy\"]=dummy_period_variables.index.isin(covid).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_period_variables.reset_index(inplace = True)\n",
    "dummy_period_variables = dummy_period_variables.rename(columns = {'index':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>ss_dummy</th>\n",
       "      <th>covid_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  ss_dummy  covid_dummy\n",
       "0    2018-07-02         0            0\n",
       "1    2018-07-03         0            0\n",
       "2    2018-07-04         0            0\n",
       "3    2018-07-05         0            0\n",
       "4    2018-07-06         0            0\n",
       "...         ...       ...          ...\n",
       "1517 2022-08-27         0            0\n",
       "1518 2022-08-28         0            0\n",
       "1519 2022-08-29         0            0\n",
       "1520 2022-08-30         0            0\n",
       "1521 2022-08-31         0            0\n",
       "\n",
       "[1522 rows x 3 columns]"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_period_variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MEF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "mef = pd.read_excel(path.join(data_folder,'mef_irrbb.xlsx'))\n",
    "mef.Date = pd.to_datetime(mef.Date, errors = 'coerce')\n",
    "df_add = pd.DataFrame(columns = mef.columns[1:], data = np.nan, index = pd.date_range(st_date,end_date)).reset_index().rename(columns = {'index':'Date'})\n",
    "mef_new = df_add.append(mef)\n",
    "mef_new.sort_values('Date', ascending = True, inplace = True)\n",
    "mef_final = mef_new.fillna(method = 'ffill')\n",
    "mef_final = mef_final[(mef_final.Date >= st_date) & (mef_final.Date <= end_date)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Term</th>\n",
       "      <th>MSB_1M</th>\n",
       "      <th>MSB_3M</th>\n",
       "      <th>MSB_6M</th>\n",
       "      <th>MSB_9M</th>\n",
       "      <th>MSB_12M</th>\n",
       "      <th>MSB_13M</th>\n",
       "      <th>MSB_15M</th>\n",
       "      <th>MSB_18M</th>\n",
       "      <th>MSB_24M</th>\n",
       "      <th>MSB_36M</th>\n",
       "      <th>...</th>\n",
       "      <th>MSB_G2_9M</th>\n",
       "      <th>MSB_G2_12M</th>\n",
       "      <th>MSB_G2_13M</th>\n",
       "      <th>MSB_G2_15M</th>\n",
       "      <th>MSB_G2_18M</th>\n",
       "      <th>MSB_G2_24M</th>\n",
       "      <th>MSB_G2_36M</th>\n",
       "      <th>MSB_G2_Short_Term</th>\n",
       "      <th>MSB_G2_Medium_Term</th>\n",
       "      <th>MSB_G2_Long_Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-07-02</th>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-03</th>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-04</th>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-06</th>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-27</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-28</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-29</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-30</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-31</th>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Term          MSB_1M  MSB_3M  MSB_6M  MSB_9M  MSB_12M  MSB_13M  MSB_15M  \\\n",
       "2018-07-02  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "2018-07-03  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "2018-07-04  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "2018-07-05  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "2018-07-06  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "...              ...     ...     ...     ...      ...      ...      ...   \n",
       "2022-08-27  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "2022-08-28  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "2022-08-29  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "2022-08-30  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "2022-08-31  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "\n",
       "Term        MSB_18M  MSB_24M  MSB_36M  ...  MSB_G2_9M  MSB_G2_12M  MSB_G2_13M  \\\n",
       "2018-07-02     6.95     6.85     6.85  ...   0.131250   -0.406250   -0.456250   \n",
       "2018-07-03     6.95     6.85     6.85  ...   0.131250   -0.406250   -0.456250   \n",
       "2018-07-04     6.95     6.85     6.85  ...   0.131250   -0.406250   -0.456250   \n",
       "2018-07-05     6.95     6.85     6.85  ...   0.131250   -0.406250   -0.456250   \n",
       "2018-07-06     6.95     6.85     6.85  ...   0.131250   -0.406250   -0.456250   \n",
       "...             ...      ...      ...  ...        ...         ...         ...   \n",
       "2022-08-27     5.75     5.75     5.75  ...  -0.675417   -0.649375    0.166458   \n",
       "2022-08-28     5.75     5.75     5.75  ...  -0.675417   -0.649375    0.166458   \n",
       "2022-08-29     5.75     5.75     5.75  ...  -0.675417   -0.649375    0.166458   \n",
       "2022-08-30     5.75     5.75     5.75  ...  -0.675417   -0.649375    0.166458   \n",
       "2022-08-31     5.75     5.75     5.75  ...  -0.675417   -0.649375    0.166458   \n",
       "\n",
       "Term        MSB_G2_15M  MSB_G2_18M  MSB_G2_24M  MSB_G2_36M  MSB_G2_Short_Term  \\\n",
       "2018-07-02   -0.287500    -0.50625   -0.825000   -0.900000           0.085333   \n",
       "2018-07-03   -0.287500    -0.50625   -0.825000   -0.900000           0.085333   \n",
       "2018-07-04   -0.287500    -0.50625   -0.825000   -0.900000           0.085333   \n",
       "2018-07-05   -0.287500    -0.50625   -0.825000   -0.900000           0.085333   \n",
       "2018-07-06   -0.287500    -0.50625   -0.825000   -0.900000           0.085333   \n",
       "...                ...         ...         ...         ...                ...   \n",
       "2022-08-27   -0.892222    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "2022-08-28   -0.892222    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "2022-08-29   -0.892222    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "2022-08-30   -0.892222    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "2022-08-31   -0.892222    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "\n",
       "Term        MSB_G2_Medium_Term  MSB_G2_Long_Term  \n",
       "2018-07-02            0.221875         -0.563542  \n",
       "2018-07-03            0.221875         -0.563542  \n",
       "2018-07-04            0.221875         -0.563542  \n",
       "2018-07-05            0.221875         -0.563542  \n",
       "2018-07-06            0.221875         -0.563542  \n",
       "...                        ...               ...  \n",
       "2022-08-27           -0.580104         -0.688218  \n",
       "2022-08-28           -0.580104         -0.688218  \n",
       "2022-08-29           -0.580104         -0.688218  \n",
       "2022-08-30           -0.580104         -0.688218  \n",
       "2022-08-31           -0.580104         -0.688218  \n",
       "\n",
       "[1522 rows x 39 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IR_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IR_variable.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Term</th>\n",
       "      <th>index</th>\n",
       "      <th>MSB_1M</th>\n",
       "      <th>MSB_3M</th>\n",
       "      <th>MSB_6M</th>\n",
       "      <th>MSB_9M</th>\n",
       "      <th>MSB_12M</th>\n",
       "      <th>MSB_13M</th>\n",
       "      <th>MSB_15M</th>\n",
       "      <th>MSB_18M</th>\n",
       "      <th>MSB_24M</th>\n",
       "      <th>...</th>\n",
       "      <th>MSB_G2_9M</th>\n",
       "      <th>MSB_G2_12M</th>\n",
       "      <th>MSB_G2_13M</th>\n",
       "      <th>MSB_G2_15M</th>\n",
       "      <th>MSB_G2_18M</th>\n",
       "      <th>MSB_G2_24M</th>\n",
       "      <th>MSB_G2_36M</th>\n",
       "      <th>MSB_G2_Short_Term</th>\n",
       "      <th>MSB_G2_Medium_Term</th>\n",
       "      <th>MSB_G2_Long_Term</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.90</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131250</td>\n",
       "      <td>-0.406250</td>\n",
       "      <td>-0.456250</td>\n",
       "      <td>-0.287500</td>\n",
       "      <td>-0.50625</td>\n",
       "      <td>-0.825000</td>\n",
       "      <td>-0.900000</td>\n",
       "      <td>0.085333</td>\n",
       "      <td>0.221875</td>\n",
       "      <td>-0.563542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>3.700000</td>\n",
       "      <td>3.900</td>\n",
       "      <td>5.25</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>5.75</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.675417</td>\n",
       "      <td>-0.649375</td>\n",
       "      <td>0.166458</td>\n",
       "      <td>-0.892222</td>\n",
       "      <td>-0.83125</td>\n",
       "      <td>-0.857708</td>\n",
       "      <td>-1.065208</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>-0.580104</td>\n",
       "      <td>-0.688218</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Term      index    MSB_1M  MSB_3M  MSB_6M  MSB_9M  MSB_12M  MSB_13M  MSB_15M  \\\n",
       "0    2018-07-02  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "1    2018-07-03  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "2    2018-07-04  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "3    2018-07-05  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "4    2018-07-06  5.158167   5.375    6.90     6.9     6.90     6.95     7.15   \n",
       "...         ...       ...     ...     ...     ...      ...      ...      ...   \n",
       "1517 2022-08-27  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "1518 2022-08-28  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "1519 2022-08-29  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "1520 2022-08-30  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "1521 2022-08-31  3.700000   3.900    5.25     5.2     5.75     5.75     5.75   \n",
       "\n",
       "Term  MSB_18M  MSB_24M  ...  MSB_G2_9M  MSB_G2_12M  MSB_G2_13M  MSB_G2_15M  \\\n",
       "0        6.95     6.85  ...   0.131250   -0.406250   -0.456250   -0.287500   \n",
       "1        6.95     6.85  ...   0.131250   -0.406250   -0.456250   -0.287500   \n",
       "2        6.95     6.85  ...   0.131250   -0.406250   -0.456250   -0.287500   \n",
       "3        6.95     6.85  ...   0.131250   -0.406250   -0.456250   -0.287500   \n",
       "4        6.95     6.85  ...   0.131250   -0.406250   -0.456250   -0.287500   \n",
       "...       ...      ...  ...        ...         ...         ...         ...   \n",
       "1517     5.75     5.75  ...  -0.675417   -0.649375    0.166458   -0.892222   \n",
       "1518     5.75     5.75  ...  -0.675417   -0.649375    0.166458   -0.892222   \n",
       "1519     5.75     5.75  ...  -0.675417   -0.649375    0.166458   -0.892222   \n",
       "1520     5.75     5.75  ...  -0.675417   -0.649375    0.166458   -0.892222   \n",
       "1521     5.75     5.75  ...  -0.675417   -0.649375    0.166458   -0.892222   \n",
       "\n",
       "Term  MSB_G2_18M  MSB_G2_24M  MSB_G2_36M  MSB_G2_Short_Term  \\\n",
       "0       -0.50625   -0.825000   -0.900000           0.085333   \n",
       "1       -0.50625   -0.825000   -0.900000           0.085333   \n",
       "2       -0.50625   -0.825000   -0.900000           0.085333   \n",
       "3       -0.50625   -0.825000   -0.900000           0.085333   \n",
       "4       -0.50625   -0.825000   -0.900000           0.085333   \n",
       "...          ...         ...         ...                ...   \n",
       "1517    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "1518    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "1519    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "1520    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "1521    -0.83125   -0.857708   -1.065208           0.070000   \n",
       "\n",
       "Term  MSB_G2_Medium_Term  MSB_G2_Long_Term  \n",
       "0               0.221875         -0.563542  \n",
       "1               0.221875         -0.563542  \n",
       "2               0.221875         -0.563542  \n",
       "3               0.221875         -0.563542  \n",
       "4               0.221875         -0.563542  \n",
       "...                  ...               ...  \n",
       "1517           -0.580104         -0.688218  \n",
       "1518           -0.580104         -0.688218  \n",
       "1519           -0.580104         -0.688218  \n",
       "1520           -0.580104         -0.688218  \n",
       "1521           -0.580104         -0.688218  \n",
       "\n",
       "[1522 rows x 40 columns]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IR_variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_variable.rename(columns = {'index':'Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg = wd_reg.rename(columns = {'index':'Date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = wd_reg.merge((IR_variable.merge(mef_final, how = 'left', on = ['Date'])).\n",
    "                merge(dummy_period_variables, how = 'left', on = ['Date']), how = 'left', on = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>VND_RC_WD_0-30</th>\n",
       "      <th>VND_RC_WD_30-90</th>\n",
       "      <th>VND_RC_WD_90-180</th>\n",
       "      <th>VND_RC_WD_180-365</th>\n",
       "      <th>VND_RC_WD_365-730</th>\n",
       "      <th>VND_RC_WD_730-1095</th>\n",
       "      <th>VND_RC_WD_1095-1460</th>\n",
       "      <th>VND_RC_WD_1825-2190</th>\n",
       "      <th>VND_RC_WD_1460-1825</th>\n",
       "      <th>...</th>\n",
       "      <th>GDP_lead_6m</th>\n",
       "      <th>GDP_lead_9m</th>\n",
       "      <th>GDP_lead_12m</th>\n",
       "      <th>GDP_per_change</th>\n",
       "      <th>GDP_ma_3m</th>\n",
       "      <th>GDP_ma_6m</th>\n",
       "      <th>GDP_ma_9m</th>\n",
       "      <th>GDP_ma_12m</th>\n",
       "      <th>ss_dummy</th>\n",
       "      <th>covid_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.230</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>0.015120</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.230</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.230</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.230</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.040650</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.230</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1533</th>\n",
       "      <td>2022-08-27</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>7.72</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>2022-08-28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>7.72</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>2022-08-29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>7.72</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1536</th>\n",
       "      <td>2022-08-30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>7.72</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1537</th>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.65</td>\n",
       "      <td>6.15</td>\n",
       "      <td>6.40</td>\n",
       "      <td>0.534791</td>\n",
       "      <td>7.72</td>\n",
       "      <td>6.375</td>\n",
       "      <td>5.99</td>\n",
       "      <td>2.9500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1538 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date  VND_RC_WD_0-30  VND_RC_WD_30-90  VND_RC_WD_90-180  \\\n",
       "0    2018-07-02        0.015092         0.006141          0.009348   \n",
       "1    2018-07-03        0.015120         0.006373          0.009227   \n",
       "2    2018-07-04        0.016331         0.006419          0.008904   \n",
       "3    2018-07-05        0.015359         0.006518          0.008632   \n",
       "4    2018-07-06        0.016748         0.006723          0.008750   \n",
       "...         ...             ...              ...               ...   \n",
       "1533 2022-08-27             NaN              NaN               NaN   \n",
       "1534 2022-08-28             NaN              NaN               NaN   \n",
       "1535 2022-08-29             NaN              NaN               NaN   \n",
       "1536 2022-08-30             NaN              NaN               NaN   \n",
       "1537 2022-08-31             NaN              NaN               NaN   \n",
       "\n",
       "      VND_RC_WD_180-365  VND_RC_WD_365-730  VND_RC_WD_730-1095  \\\n",
       "0              0.009990           0.003566                 0.0   \n",
       "1              0.010016           0.003857                 0.0   \n",
       "2              0.009834           0.003385                 0.0   \n",
       "3              0.009862           0.003706                 0.0   \n",
       "4              0.011761           0.002607                 0.0   \n",
       "...                 ...                ...                 ...   \n",
       "1533                NaN                NaN                 NaN   \n",
       "1534                NaN                NaN                 NaN   \n",
       "1535                NaN                NaN                 NaN   \n",
       "1536                NaN                NaN                 NaN   \n",
       "1537                NaN                NaN                 NaN   \n",
       "\n",
       "      VND_RC_WD_1095-1460  VND_RC_WD_1825-2190  VND_RC_WD_1460-1825  ...  \\\n",
       "0                     0.0                  NaN                  NaN  ...   \n",
       "1                     0.0                  NaN                  NaN  ...   \n",
       "2                     0.0                  NaN                  NaN  ...   \n",
       "3                     0.0                  NaN                  NaN  ...   \n",
       "4                     0.0                  NaN                  NaN  ...   \n",
       "...                   ...                  ...                  ...  ...   \n",
       "1533                  NaN                  NaN                  NaN  ...   \n",
       "1534                  NaN                  NaN                  NaN  ...   \n",
       "1535                  NaN                  NaN                  NaN  ...   \n",
       "1536                  NaN                  NaN                  NaN  ...   \n",
       "1537                  NaN                  NaN                  NaN  ...   \n",
       "\n",
       "      GDP_lead_6m  GDP_lead_9m  GDP_lead_12m  GDP_per_change  GDP_ma_3m  \\\n",
       "0            7.31         6.82          6.73       -0.040650       7.08   \n",
       "1            7.31         6.82          6.73       -0.040650       7.08   \n",
       "2            7.31         6.82          6.73       -0.040650       7.08   \n",
       "3            7.31         6.82          6.73       -0.040650       7.08   \n",
       "4            7.31         6.82          6.73       -0.040650       7.08   \n",
       "...           ...          ...           ...             ...        ...   \n",
       "1533         6.65         6.15          6.40        0.534791       7.72   \n",
       "1534         6.65         6.15          6.40        0.534791       7.72   \n",
       "1535         6.65         6.15          6.40        0.534791       7.72   \n",
       "1536         6.65         6.15          6.40        0.534791       7.72   \n",
       "1537         6.65         6.15          6.40        0.534791       7.72   \n",
       "\n",
       "      GDP_ma_6m  GDP_ma_9m  GDP_ma_12m  ss_dummy  covid_dummy  \n",
       "0         7.230       7.37      7.3925         0            0  \n",
       "1         7.230       7.37      7.3925         0            0  \n",
       "2         7.230       7.37      7.3925         0            0  \n",
       "3         7.230       7.37      7.3925         0            0  \n",
       "4         7.230       7.37      7.3925         0            0  \n",
       "...         ...        ...         ...       ...          ...  \n",
       "1533      6.375       5.99      2.9500         0            0  \n",
       "1534      6.375       5.99      2.9500         0            0  \n",
       "1535      6.375       5.99      2.9500         0            0  \n",
       "1536      6.375       5.99      2.9500         0            0  \n",
       "1537      6.375       5.99      2.9500         0            0  \n",
       "\n",
       "[1538 rows x 79 columns]"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IR_variable = IR_variable[IR_variable.columns[2:].tolist()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phân tích hồi quy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_IR_with_correlation(IR_variable,test_size=0,max_corr=0.65):\n",
    "    IR_corr_matrix=IR_variable.iloc[:(None if test_size==0 else -test_size)].corr()\n",
    "    # lựa chọn tập X trên threshold correlation\n",
    "    sign=(IR_corr_matrix.abs()<max_corr).astype(int)\n",
    "    list_variables=IR_variable.columns.tolist()\n",
    "    list_X_feature=[[i] for i in list_variables]\n",
    "    for n in range(2, len(list_variables)+1):\n",
    "        check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "        if len(check_n_1)==0:\n",
    "            break\n",
    "        list_X_feature_n=[]\n",
    "        for a in check_n_1:\n",
    "            list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            # maximum 4 variables (include intercept)\n",
    "            \n",
    "            list_X_feature_n= [i for i in list_X_feature_n if len(i)<5] \n",
    "        list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist()\n",
    "    return list_X_feature\n",
    "#IR_list=[None]+filter_IR_with_correlation(IR_variable,test_size=0,max_corr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var = data_reg[data_reg.columns[7:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_var = [None]+filter_IR_with_correlation(all_var,test_size=0,max_corr=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handling_data_plot(df,tw,c=\"VND\",b=\"RB\",per=None,test_size=test_size,type_adjust=[\"max\"]):\n",
    "    df=df.copy()\n",
    "    x=df.index\n",
    "    x_end_train=x[-test_size]\n",
    "    df.columns=[\"Real\",\"Predict\"]\n",
    "    \n",
    "    # Cách hiệu chỉnh\n",
    "    for type_adjust in [\"max\",\"normal\",\"seasonal\"]:\n",
    "        if type_adjust==\"max\":\n",
    "            adjust_reg=(df[\"Real\"]-df[\"Predict\"]).loc[:x_end_train-pd.Timedelta(\"1D\")].max()\n",
    "            df[\"Predict_adjust_{}\".format(type_adjust)]=df[\"Predict\"]+adjust_reg\n",
    "            print(\"Giá trị hiệu chỉnh {} (%) = \".format(type_adjust),round(adjust_reg,2))\n",
    "        if type_adjust==\"normal\":\n",
    "            percentile_adjust=90\n",
    "            adjust_reg=np.nanpercentile((df[\"Real\"]-df[\"Predict\"]).loc[df.index.isin(ss_day_t0)==False].dropna().loc[:x_end_train-pd.Timedelta(\"1D\")].iloc[-365:],percentile_adjust)\n",
    "            df[\"Predict_adjust_{}\".format(type_adjust)]=df[\"Predict\"]+adjust_reg\n",
    "            print(\"Giá trị hiệu chỉnh {} (%) = \".format(type_adjust),round(adjust_reg,2))\n",
    "        if type_adjust==\"seasonal\":\n",
    "            percentile_adjust=90\n",
    "            adjust_reg=np.nanpercentile((df[\"Real\"]-df[\"Predict\"]).loc[df.index.isin(ss_day_t0)].dropna().loc[:x_end_train-pd.Timedelta(\"1D\")],percentile_adjust)\n",
    "            df[\"Predict_adjust_{}\".format(type_adjust)]=df[\"Predict\"]+adjust_reg\n",
    "            print(\"Giá trị hiệu chỉnh {} (%) = \".format(type_adjust),round(adjust_reg,2))\n",
    "    #     if type_adjust==\"stress\":\n",
    "    #         percentile_adjust=-10\n",
    "    #         adjust_reg=np.sort((df[\"Real\"]-df[\"Predict\"]).dropna().loc[:x_end_train-pd.Timedelta(\"1D\")])[percentile_adjust]\n",
    "    #         df[\"Predict_adjust_{}\".format(type_adjust)]=df[\"Predict\"]+adjust_reg\n",
    "    df[\"mix_regression\"]=(df.index.isin(st_msb)*df[\"Predict_adjust_max\"])+\\\n",
    "        ((df.index.isin(ss_day_t0) & (df.index.isin(st_msb)==False))*df[\"Predict_adjust_seasonal\"])+\\\n",
    "        (((df.index.isin(ss_day_t0)==False) & (df.index.isin(st_msb)==False))*df[\"Predict_adjust_normal\"])\n",
    "    \n",
    "    \n",
    "    if per is not None:\n",
    "        per_filter=per.loc[(per.CURTYP==c) & (per.bank==b)].set_index(\"Time\").loc[:,(\"WD_PRE_RATIO\",tw)]\n",
    "        per_filter.values\n",
    "        df[per_filter.index]=per_filter.values*100\n",
    "        df[\"mix_percentile\"]=(df.index.isin(st_msb)*df.Stress)+\\\n",
    "        ((df.index.isin(ss_day_t0) & (df.index.isin(st_msb)==False))*df.Seasonal)+\\\n",
    "        (((df.index.isin(ss_day_t0)==False) & (df.index.isin(st_msb)==False))*df.Normal)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reg(df,tw,test_size,b,c,figsize=(10, 4),dpi=100):\n",
    "    x=df.index\n",
    "    x_end_train=x[-test_size]\n",
    "    fig, ax = plt.subplots(1, figsize=figsize,dpi=dpi)\n",
    "    ax.set_title(\"Mô hình hồi quy danh mục {} {} Time-window {} ngày\".format(b,c,tw).upper())\n",
    "    ax.grid(alpha=0.3)\n",
    "\n",
    "    ax.fill_between(x, 0, df[\"Real\"], alpha=0.1,color=\"gray\")\n",
    "    ax.fill_between(x, 0,df.loc[df.index.isin(covid),\"Real\"].reindex(x),color=\"orange\", alpha=0.2,label=\"Covid Period\",hatch='.')\n",
    "    ax.fill_between(x, 0,df.loc[df.index.isin(ss_day_t0),\"Real\"].reindex(x),color=\"violet\", alpha=0.3,label=\"Seasonal Period\")\n",
    "    \n",
    "    ax.plot(x,df[\"Predict\"],color=\"goldenrod\",label=\"Tỷ lệ Rút hồi quy\",alpha=0.7,linewidth=0.7)\n",
    "    \n",
    "    ax.plot(x,(df[\"Predict_adjust_normal\"]),\"g-\",label=\"Tỷ lệ rút normal regression\",alpha=0.7,linewidth=0.7)\n",
    "    ax.plot(x,(df[\"Predict_adjust_seasonal\"]),\"b-\",label=\"Tỷ lệ rút seasonal regression\",alpha=0.7,linewidth=0.7)\n",
    "#     ax.plot(x,(df[\"Predict_adjust_max\"]),color=\"violet\",ls=\"-\",label=\"Tỷ lệ rút stress regression\",alpha=0.7,linewidth=0.7)\n",
    "    \n",
    "    ax.plot(x,df[\"Real\"],color=\"gray\",label=\"Tỷ lệ Rút thực tế\")\n",
    "    ax.plot(x,(df[\"mix_regression\"]),ls=\"-\",color=\"orangered\",label=\"Tỷ lệ rút hồi quy hiệu chỉnh\",linewidth=1.5) \n",
    "\n",
    "    ax.legend(ncol=3,loc=\"upper left\")\n",
    "    ax.vlines(x=x_end_train, ymin=0, ymax=df.max().max()*1.2,ls=\"--\",color=\"green\",linewidth=2)\n",
    "    ax.annotate(text=\"Test Period\",xy=(x_end_train+pd.Timedelta(\"3D\"),df.max().max()))\n",
    "#     ax.set_ylim( 0, df.max().max()*1.2)\n",
    "    ax.set_ylabel(\"%\")\n",
    "    ax.set_xlabel('Begin date')\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mix(df,tw,test_size,b,c,figsize=(10, 4),dpi=100):\n",
    "    x=df.index\n",
    "    x_end_train=x[-test_size]\n",
    "    fig, ax = plt.subplots(1, figsize=figsize,dpi=dpi)\n",
    "    ax.set_title(\"So sánh mô hình hồi quy và percentile danh mục {} {} Time-window {} ngày\".format(b,c,tw).upper())\n",
    "    ax.grid(alpha=0.3)\n",
    "        \n",
    "    ax.plot(x,(df[\"Predict\"]),ls=\"-\",color=\"deepskyblue\",label=\"Tỷ lệ rút hồi quy\",alpha=0.7,linewidth=0.7) # olive\n",
    "    \n",
    "    ax.plot(x,df[\"Real\"],color=\"gray\",label=\"Tỷ lệ Rút thực tế\")\n",
    "    ax.fill_between(x, 0, df[\"Real\"], alpha=0.1,color=\"gray\")\n",
    "    ax.fill_between(x, 0,df.loc[df.index.isin(covid),\"Real\"].reindex(x),color=\"orange\", alpha=0.2,label=\"Covid Period\",hatch='.')\n",
    "    ax.fill_between(x, 0,df.loc[df.index.isin(ss_day_t0),\"Real\"].reindex(x),color=\"violet\", alpha=0.3,label=\"Seasonal Period\")\n",
    "    \n",
    "    ax.plot(x,(df[\"mix_regression\"]),ls=\"-\",color=\"orangered\",label=\"Tỷ lệ rút hồi quy sau hiệu chỉnh\",alpha=0.7) # olive\n",
    "    ax.plot(x,(df[\"Normal\"]),\"y--\",label=\"Tỷ lệ rút percentile normal\",alpha=0.7)\n",
    "    ax.plot(x,(df[\"Seasonal\"]),\"g--\",label=\"Tỷ lệ rút percentile seasonal\",alpha=0.7)\n",
    "    ax.plot(x,(df[\"Stress\"]),\"b--\",label=\"Tỷ lệ rút percentile stress\",alpha=0.7)\n",
    "    \n",
    "    \n",
    "    \n",
    "    ax.legend(ncol=3,loc=\"upper left\")\n",
    "    ax.vlines(x=x_end_train, ymin=0, ymax=df.max().max()*1.4,ls=\"--\",color=\"green\",linewidth=2)\n",
    "    ax.annotate(text=\"Test Period\",xy=(x_end_train+pd.Timedelta(\"3D\"),df.max().max()))\n",
    "    ax.set_ylim( 0, df.max().max()*1.4)\n",
    "    ax.set_ylabel(\"%\")\n",
    "    ax.set_xlabel('Begin date')\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_cal(df):\n",
    "    # RMSE chỉ lấy abs, ko có relative\n",
    "    \n",
    "    x=[i for i in df.columns if \"mix\" in i]\n",
    "    df[[i+\"_diff_abs\" for i in x]]=df[x].values-df[[\"Real\"]].values\n",
    "    df[[i+\"_diff_rel\" for i in x]]=(df[x].values-df[[\"Real\"]].values)/df[[\"Real\"]].values\n",
    "    df_diff=df[[i for i in df.columns if \"diff\" in i]]\n",
    "    performance=pd.concat([(df_diff.pow(2).sum()/len(df_diff)).pow(0.5),\n",
    "    df_diff.abs().max(),\n",
    "    df_diff.mean(),\n",
    "    df_diff.abs().min()],axis=1)\n",
    "    performance.columns=[\"RMSE\",\"max_diff\",\"mean_diff\",\"min_diff\"]\n",
    "    performance=performance.T\n",
    "    for i in performance.columns:\n",
    "        performance.loc[\"RMSE\",i]=performance.loc[\"RMSE\",i.replace(\"rel\",\"abs\")]\n",
    "    return performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd_reg.rename(columns = {'index':'Date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg = wd_reg.merge(all_variables, how = 'left', on = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_reg.columns[1:6].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mape(actual, pred): \n",
    "    actual, pred = np.array(actual), np.array(pred)\n",
    "    return np.mean(np.abs((actual - pred) / actual)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_column_values(df, col_idx):\n",
    "    col_data = df.iloc[:,col_idx:].values\n",
    "    res1 = []\n",
    "    res2 = []\n",
    "    for a in col_data:\n",
    "        res1.append(a[0])\n",
    "        if len(a)>1:\n",
    "            res2.append(a[1])\n",
    "    return np.array(res1), np.array(res2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var  = IR_variable.merge(mef_final, how = 'left', on = ['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>MSB_1M</th>\n",
       "      <th>MSB_3M</th>\n",
       "      <th>MSB_6M</th>\n",
       "      <th>MSB_9M</th>\n",
       "      <th>MSB_12M</th>\n",
       "      <th>MSB_13M</th>\n",
       "      <th>MSB_15M</th>\n",
       "      <th>MSB_18M</th>\n",
       "      <th>MSB_24M</th>\n",
       "      <th>...</th>\n",
       "      <th>GDP_lag_12m</th>\n",
       "      <th>GDP_lead_3m</th>\n",
       "      <th>GDP_lead_6m</th>\n",
       "      <th>GDP_lead_9m</th>\n",
       "      <th>GDP_lead_12m</th>\n",
       "      <th>GDP_per_change</th>\n",
       "      <th>GDP_ma_3m</th>\n",
       "      <th>GDP_ma_6m</th>\n",
       "      <th>GDP_ma_9m</th>\n",
       "      <th>GDP_ma_12m</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>5.158167</td>\n",
       "      <td>5.375</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.95</td>\n",
       "      <td>7.15</td>\n",
       "      <td>6.95</td>\n",
       "      <td>6.85</td>\n",
       "      <td>...</td>\n",
       "      <td>6.28</td>\n",
       "      <td>6.88</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    MSB_1M  MSB_3M  MSB_6M  MSB_9M  MSB_12M  MSB_13M  MSB_15M  \\\n",
       "0 2018-07-02  5.158167   5.375     6.9     6.9      6.9     6.95     7.15   \n",
       "1 2018-07-03  5.158167   5.375     6.9     6.9      6.9     6.95     7.15   \n",
       "2 2018-07-04  5.158167   5.375     6.9     6.9      6.9     6.95     7.15   \n",
       "3 2018-07-05  5.158167   5.375     6.9     6.9      6.9     6.95     7.15   \n",
       "4 2018-07-06  5.158167   5.375     6.9     6.9      6.9     6.95     7.15   \n",
       "\n",
       "   MSB_18M  MSB_24M  ...  GDP_lag_12m  GDP_lead_3m  GDP_lead_6m  GDP_lead_9m  \\\n",
       "0     6.95     6.85  ...         6.28         6.88         7.31         6.82   \n",
       "1     6.95     6.85  ...         6.28         6.88         7.31         6.82   \n",
       "2     6.95     6.85  ...         6.28         6.88         7.31         6.82   \n",
       "3     6.95     6.85  ...         6.28         6.88         7.31         6.82   \n",
       "4     6.95     6.85  ...         6.28         6.88         7.31         6.82   \n",
       "\n",
       "   GDP_lead_12m  GDP_per_change  GDP_ma_3m  GDP_ma_6m  GDP_ma_9m  GDP_ma_12m  \n",
       "0          6.73        -0.04065       7.08       7.23       7.37      7.3925  \n",
       "1          6.73        -0.04065       7.08       7.23       7.37      7.3925  \n",
       "2          6.73        -0.04065       7.08       7.23       7.37      7.3925  \n",
       "3          6.73        -0.04065       7.08       7.23       7.37      7.3925  \n",
       "4          6.73        -0.04065       7.08       7.23       7.37      7.3925  \n",
       "\n",
       "[5 rows x 68 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_var.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_bien(b,c,bk, wd_reg, all_var):\n",
    "    Y_var = wd_reg[[\"{}_{}_WD_{}\".format(c,b,bk)]]\n",
    "    df = pd.DataFrame()\n",
    "    for col in all_var.columns.tolist():\n",
    "        corre = all_var[col].corr(Y_var[Y_var.columns[0]])\n",
    "        corr_df = pd.DataFrame(data = {Y_var.columns[0] :[corre]}, index = [col])\n",
    "        df = df.append(corr_df)\n",
    "    df = df[(df[Y_var.columns[0]].abs() > 0.4)]\n",
    "    df.reset_index(inplace = True)\n",
    "    all_x_var_list = df['index'].unique().tolist()\n",
    "    df_reg = pd.concat([Y_var,all_var[[i for i in all_var.columns.tolist() if i in all_x_var_list]]], axis = 1)\n",
    "    return df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>VND_RC_WD_0-30</th>\n",
       "      <th>VND_RC_WD_30-90</th>\n",
       "      <th>VND_RC_WD_90-180</th>\n",
       "      <th>VND_RC_WD_180-365</th>\n",
       "      <th>VND_RC_WD_365-730</th>\n",
       "      <th>VND_RC_WD_730-1095</th>\n",
       "      <th>VND_RC_WD_1095-1460</th>\n",
       "      <th>VND_RC_WD_1825-2190</th>\n",
       "      <th>VND_RC_WD_1460-1825</th>\n",
       "      <th>...</th>\n",
       "      <th>GDP_lead_6m</th>\n",
       "      <th>GDP_lead_9m</th>\n",
       "      <th>GDP_lead_12m</th>\n",
       "      <th>GDP_per_change</th>\n",
       "      <th>GDP_ma_3m</th>\n",
       "      <th>GDP_ma_6m</th>\n",
       "      <th>GDP_ma_9m</th>\n",
       "      <th>GDP_ma_12m</th>\n",
       "      <th>ss_dummy</th>\n",
       "      <th>covid_dummy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-07-02</td>\n",
       "      <td>0.015092</td>\n",
       "      <td>0.006141</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.003566</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-07-03</td>\n",
       "      <td>0.015120</td>\n",
       "      <td>0.006373</td>\n",
       "      <td>0.009227</td>\n",
       "      <td>0.010016</td>\n",
       "      <td>0.003857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-07-04</td>\n",
       "      <td>0.016331</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.008904</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.003385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-07-05</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.006518</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.009862</td>\n",
       "      <td>0.003706</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>0.016748</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.011761</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.31</td>\n",
       "      <td>6.82</td>\n",
       "      <td>6.73</td>\n",
       "      <td>-0.04065</td>\n",
       "      <td>7.08</td>\n",
       "      <td>7.23</td>\n",
       "      <td>7.37</td>\n",
       "      <td>7.3925</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 79 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  VND_RC_WD_0-30  VND_RC_WD_30-90  VND_RC_WD_90-180  \\\n",
       "0 2018-07-02        0.015092         0.006141          0.009348   \n",
       "1 2018-07-03        0.015120         0.006373          0.009227   \n",
       "2 2018-07-04        0.016331         0.006419          0.008904   \n",
       "3 2018-07-05        0.015359         0.006518          0.008632   \n",
       "4 2018-07-06        0.016748         0.006723          0.008750   \n",
       "\n",
       "   VND_RC_WD_180-365  VND_RC_WD_365-730  VND_RC_WD_730-1095  \\\n",
       "0           0.009990           0.003566                 0.0   \n",
       "1           0.010016           0.003857                 0.0   \n",
       "2           0.009834           0.003385                 0.0   \n",
       "3           0.009862           0.003706                 0.0   \n",
       "4           0.011761           0.002607                 0.0   \n",
       "\n",
       "   VND_RC_WD_1095-1460  VND_RC_WD_1825-2190  VND_RC_WD_1460-1825  ...  \\\n",
       "0                  0.0                  NaN                  NaN  ...   \n",
       "1                  0.0                  NaN                  NaN  ...   \n",
       "2                  0.0                  NaN                  NaN  ...   \n",
       "3                  0.0                  NaN                  NaN  ...   \n",
       "4                  0.0                  NaN                  NaN  ...   \n",
       "\n",
       "   GDP_lead_6m  GDP_lead_9m  GDP_lead_12m  GDP_per_change  GDP_ma_3m  \\\n",
       "0         7.31         6.82          6.73        -0.04065       7.08   \n",
       "1         7.31         6.82          6.73        -0.04065       7.08   \n",
       "2         7.31         6.82          6.73        -0.04065       7.08   \n",
       "3         7.31         6.82          6.73        -0.04065       7.08   \n",
       "4         7.31         6.82          6.73        -0.04065       7.08   \n",
       "\n",
       "   GDP_ma_6m  GDP_ma_9m  GDP_ma_12m  ss_dummy  covid_dummy  \n",
       "0       7.23       7.37      7.3925         0            0  \n",
       "1       7.23       7.37      7.3925         0            0  \n",
       "2       7.23       7.37      7.3925         0            0  \n",
       "3       7.23       7.37      7.3925         0            0  \n",
       "4       7.23       7.37      7.3925         0            0  \n",
       "\n",
       "[5 rows x 79 columns]"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[\"{}_{}_WD_{}\".format(i[0],i[1], i[3]) for i in wd_reg.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from statsmodels.tools.tools import add_constant\n",
    "import statsmodels.stats.api as sms\n",
    "from statsmodels.formula.api import ols\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "from statsmodels.stats.stattools import durbin_watson\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.stats.diagnostic import het_white\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "import scipy.stats as stats\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def data_split(data,y,test_size=4):\n",
    "    if test_size<=1:\n",
    "        point_split=round((1-test_size)*len(data))\n",
    "    else:\n",
    "        point_split=int(len(data)-test_size)\n",
    "    x_train=data[[i for i in data.columns if i != y]].iloc[:point_split].copy()\n",
    "    y_train=data[[y]].iloc[:point_split].copy()\n",
    "    x_test=data[[i for i in data.columns if i != y]].iloc[point_split:].copy()\n",
    "    y_test=data[[y]].iloc[point_split:].copy()\n",
    "    return x_train,y_train,x_test,y_test\n",
    "\n",
    "\n",
    "\n",
    "def run_OLS(x_name, y_name,data,poly_degree=1,return_plot=False,test_size=30,return_summary=True):\n",
    "    x_name=x_name.copy()\n",
    "    if return_summary:\n",
    "        global real_y,predict_y,predict_y_test\n",
    "        \n",
    "    x_name=[x_name] if type(x_name)==str else x_name\n",
    "    number_var=len(x_name)\n",
    "          \n",
    "    data=data[[y_name]+x_name].copy().dropna()\n",
    "\n",
    "    poly=PolynomialFeatures(degree=poly_degree)\n",
    "    data_x=pd.DataFrame(poly.fit_transform(data[x_name]),columns=poly.get_feature_names(input_features=x_name),index=data.index)\n",
    "    data=pd.concat([data[y_name],data_x],axis=1).dropna()\n",
    "    data1=pd.DataFrame(data)\n",
    "    \n",
    "    x_train,y_train,x_test,y_test=data_split(data,y_name,test_size=test_size)\n",
    "#     print(len(y_train.values), len(x_train))\n",
    "    res = sm.OLS(y_train.values,x_train ).fit()\n",
    "    predict_y_test = res.predict(x_test)\n",
    "    all_y = y_train.append(y_test, ignore_index = True)\n",
    "    all_x = x_train.append(x_test, ignore_index = True)\n",
    "#     all_x = pd.concat([x_train, x_test],axis = 0)\n",
    "    predict_all_y = res.predict(all_x)\n",
    "    RMSE= np.nan if test_size==1 else np.sqrt(mean_squared_error(all_y,predict_all_y)) # Root Mean Square Error(RMSE)\n",
    "    all_res = sm.OLS(all_y.values, all_x).fit()\n",
    "#     MAPE_all = mape(all_y, predict_all_y)\n",
    "    MAPE_all_new = mean_absolute_percentage_error(all_y, predict_all_y)\n",
    "\n",
    "    \n",
    "    #Tinh cook distance\n",
    "    influence = res.get_influence()\n",
    "    cooks = influence.cooks_distance\n",
    "\n",
    "    vif = [variance_inflation_factor(data_x.values, i) \n",
    "               for i in range(data_x.shape[1])]\n",
    "    \n",
    "    #Tinh MAPE\n",
    "    MAPE_result = mape(y_test,predict_y_test)\n",
    "\n",
    "    if return_plot==False: \n",
    "        \n",
    "        num_inappropriate_pvalue=int(sum(res.pvalues>0.05))\n",
    "        f_pvalue=res.f_pvalue\n",
    "        cooks = res.get_influence().cooks_distance\n",
    "        D_W = durbin_watson(res.resid)\n",
    "        \n",
    "        #Tinh residuals\n",
    "        residuals = np.array(y_test) - np.array(predict_y_test)\n",
    "         # Calculate ks\n",
    "        ks_data_x1, ks_data_x2 = get_dataframe_column_values(data1, 2)\n",
    "        \n",
    "        ks_data_y, _ = get_dataframe_column_values(data1, 0)\n",
    "        \n",
    "        ks1 = ks_2samp(ks_data_x1, ks_data_y)\n",
    "        ks2 = ks1\n",
    "        \n",
    "        ks3 = kstest(res.resid,'norm', alternative = 'greater')\n",
    "        #Tinh Dickey_fuller\n",
    "        ADF_y = adfuller(ks_data_y)\n",
    "        ADF_x1 = adfuller(ks_data_x1)\n",
    "        ADF_x2 = ADF_x1\n",
    "        ADF_resid_AIC = adfuller(res.resid, autolag='AIC')\n",
    "        ADF_resid_BIC = adfuller(res.resid, autolag='BIC')\n",
    "\n",
    "        if len(ks_data_x2) > 0:\n",
    "            ks2 = ks_2samp(ks_data_x2, ks_data_y)\n",
    "            ADF_x2 = adfuller(ks_data_x2)\n",
    "            \n",
    "        ##Count %Cooks Value Pass\n",
    "        result = []\n",
    "        for i in range(len(cooks[0].tolist())):\n",
    "            if cooks[0].tolist()[i] <= 4/len(data1):\n",
    "                result.append(cooks[0].tolist()[i])\n",
    "            i = i + 1\n",
    "        result = len(result)/len(cooks[0].tolist()) \n",
    "        \n",
    "#         Tinh White_het\n",
    "        White=0\n",
    "        try:\n",
    "            white_test = het_white(res.resid,  res.model.exog)\n",
    "            labels = ['Test Statistic', 'Test Statistic p-value', 'F-Statistic', 'F-Test p-value']\n",
    "            WhiteObj = dict(zip(labels, white_test))\n",
    "            White = WhiteObj['Test Statistic p-value']\n",
    "        except:\n",
    "            White = {\"Error\":\"AssertionErr\"}\n",
    "        \n",
    "        df_result=pd.DataFrame().reindex(x_train.columns)\n",
    "        df_result=pd.DataFrame(\n",
    "            [y_name,res.params.index.tolist(),number_var+1,poly_degree,num_inappropriate_pvalue,\n",
    "             res.rsquared,res.rsquared_adj, res.pvalues.tolist(), f_pvalue,RMSE,res.params.tolist(),\n",
    "             cooks[0].max(), result,D_W,vif, ks3.pvalue, ADF_resid_AIC[1], ADF_resid_BIC[1],White,\n",
    "            MAPE_all_new],\n",
    "            index=[\"Y_feature\",\"X_feature\",\"number_var\",\"degree_poly\",\"num_inappropriate_pvalue\",\"R_2\",\"Adj_R_2\",\n",
    "                   \"P_value\", \"f_pvalue\",\"RMSE\",\"Coef\",\"Cooks's Distance Max\",\"%Cooks Value Pass\",\"Durbin Watson\",\"VIF\", \n",
    "                   \"KS test\", \"ADF test AIC\", \"ADF test BIC\",\"White_test\",  \"MAPE of all\"]).T\n",
    "        return df_result\n",
    "    else:\n",
    "        x = data.index\n",
    "        real_y = data[y_name]\n",
    "        predict_y = res.get_prediction(data_x).summary_frame(alpha=0).iloc[:,0]\n",
    "        fig,ax  = plt.subplots(1,figsize=(10,4))\n",
    "        ax.plot(x,real_y)\n",
    "        ax.plot(x,predict_y,lw=1.5)\n",
    "        ax.plot(y_test.index,predict_y_test, 'g',lw=1.5)\n",
    "        ax.legend([\"Real\",\"Estimate\",\"Predict\"])\n",
    "        plt.show()\n",
    "        \n",
    "        if return_summary:\n",
    "            print(RMSE)\n",
    "#             print(f'MAPE logit new {MAPE_all_logit_new}')\n",
    "#             print(f'MAPE ODR new {MAPE_all_ODR_new}')\n",
    "            return res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'VND_RC_WD_0-30', 'VND_RC_WD_30-90', 'VND_RC_WD_90-180',\n",
       "       'VND_RC_WD_180-365', 'VND_RC_WD_365-730', 'VND_RC_WD_730-1095',\n",
       "       'VND_RC_WD_1095-1460', 'VND_RC_WD_1825-2190', 'VND_RC_WD_1460-1825',\n",
       "       'MSB_1M', 'MSB_3M', 'MSB_6M', 'MSB_9M', 'MSB_12M', 'MSB_13M', 'MSB_15M',\n",
       "       'MSB_18M', 'MSB_24M', 'MSB_36M', 'MSB_Short_Term', 'MSB_Medium_Term',\n",
       "       'MSB_Long_Term', 'MSB_G1_1M', 'MSB_G1_3M', 'MSB_G1_6M', 'MSB_G1_9M',\n",
       "       'MSB_G1_12M', 'MSB_G1_13M', 'MSB_G1_15M', 'MSB_G1_18M', 'MSB_G1_24M',\n",
       "       'MSB_G1_36M', 'MSB_G1_Short_Term', 'MSB_G1_Medium_Term',\n",
       "       'MSB_G1_Long_Term', 'MSB_G2_1M', 'MSB_G2_3M', 'MSB_G2_6M', 'MSB_G2_9M',\n",
       "       'MSB_G2_12M', 'MSB_G2_13M', 'MSB_G2_15M', 'MSB_G2_18M', 'MSB_G2_24M',\n",
       "       'MSB_G2_36M', 'MSB_G2_Short_Term', 'MSB_G2_Medium_Term',\n",
       "       'MSB_G2_Long_Term', 'CPI_YoY_Index', 'CPI_YoY_Index_lag_3m',\n",
       "       'CPI_YoY_Index_lag_6m', 'CPI_YoY_Index_lag_9m', 'CPI_YoY_Index_lag_12m',\n",
       "       'CPI_YoY_Index_lead_3m', 'CPI_YoY_Index_lead_6m',\n",
       "       'CPI_YoY_Index_lead_9m', 'CPI_YoY_Index_lead_12m',\n",
       "       'CPI_YoY_Index_per_change', 'CPI_YoY_Index_ma_3m',\n",
       "       'CPI_YoY_Index_ma_6m', 'CPI_YoY_Index_ma_9m', 'CPI_YoY_Index_ma_12m',\n",
       "       'GDP', 'GDP_lag_3m', 'GDP_lag_6m', 'GDP_lag_9m', 'GDP_lag_12m',\n",
       "       'GDP_lead_3m', 'GDP_lead_6m', 'GDP_lead_9m', 'GDP_lead_12m',\n",
       "       'GDP_per_change', 'GDP_ma_3m', 'GDP_ma_6m', 'GDP_ma_9m', 'GDP_ma_12m',\n",
       "       'ss_dummy', 'covid_dummy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Y_feature</th>\n",
       "      <th>X_feature</th>\n",
       "      <th>number_var</th>\n",
       "      <th>degree_poly</th>\n",
       "      <th>num_inappropriate_pvalue</th>\n",
       "      <th>R_2</th>\n",
       "      <th>Adj_R_2</th>\n",
       "      <th>P_value</th>\n",
       "      <th>f_pvalue</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>Coef</th>\n",
       "      <th>Cooks's Distance Max</th>\n",
       "      <th>%Cooks Value Pass</th>\n",
       "      <th>Durbin Watson</th>\n",
       "      <th>VIF</th>\n",
       "      <th>KS test</th>\n",
       "      <th>ADF test AIC</th>\n",
       "      <th>ADF test BIC</th>\n",
       "      <th>White_test</th>\n",
       "      <th>MAPE of all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VND_RC_WD_180</td>\n",
       "      <td>[1, GDP, MSB_24M, covid_dummy]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496894</td>\n",
       "      <td>0.495752</td>\n",
       "      <td>[1.499619318028659e-276, 0.15108184566018878, ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010047</td>\n",
       "      <td>[0.1317097216805077, 0.00013015728240558768, -...</td>\n",
       "      <td>0.01352</td>\n",
       "      <td>0.96003</td>\n",
       "      <td>0.118202</td>\n",
       "      <td>[109.37352542291504, 1.4582002106674201, 1.463...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026954</td>\n",
       "      <td>0.011267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Y_feature                       X_feature number_var degree_poly  \\\n",
       "0  VND_RC_WD_180  [1, GDP, MSB_24M, covid_dummy]          4           1   \n",
       "\n",
       "  num_inappropriate_pvalue       R_2   Adj_R_2  \\\n",
       "0                        1  0.496894  0.495752   \n",
       "\n",
       "                                             P_value f_pvalue      RMSE  \\\n",
       "0  [1.499619318028659e-276, 0.15108184566018878, ...      0.0  0.010047   \n",
       "\n",
       "                                                Coef Cooks's Distance Max  \\\n",
       "0  [0.1317097216805077, 0.00013015728240558768, -...              0.01352   \n",
       "\n",
       "  %Cooks Value Pass Durbin Watson  \\\n",
       "0           0.96003      0.118202   \n",
       "\n",
       "                                                 VIF KS test ADF test AIC  \\\n",
       "0  [109.37352542291504, 1.4582002106674201, 1.463...     0.0     0.026954   \n",
       "\n",
       "  ADF test BIC White_test MAPE of all  \n",
       "0     0.011267        0.0     0.19799  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# return_to = None                 # detail plot_reg plot_mix backtest_mix\n",
    "(run_OLS(['GDP','MSB_24M','covid_dummy'], 'VND_RC_WD_180',data=data_reg.copy(),poly_degree=1,return_plot=False,test_size=30,return_summary=False))#.to_excel(\"vnd_090_add.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2173934651740688"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_reg['GDP'].corr(data_reg['VND_RC_WD_365'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' hàm OLS để ra y predict và vẽ hình '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' hàm OLS để ra y predict và vẽ hình '''\n",
    "''' new '''\n",
    "def run_OLS(b,c,tw,ir_names=IR_list[100],dummy_names=[\"ss_dummy\",\"covid_dummy\"],wd_reg=wd_reg,return_to=\"overview\",test_size=test_size,save_fig=False,per=per,figsize=(10, 4),dpi=100):\n",
    "    y=wd_reg[\"{}_{}_WD_{}\".format(c,b,tw)].iloc[:-(int(tw.split('-')[1].split('D')[0]))].copy()*100\n",
    "    const_x=pd.DataFrame([[1]]*len(wd_reg.index),index=wd_reg.index,columns=[\"const\"])\n",
    "    ir_x=None if ((ir_names is None) | (c==\"USD\")) else IR_variable[ir_names].copy()\n",
    "    dummy_x=None if (dummy_names is None) else dummy_period_variables[dummy_names].copy()\n",
    "    \n",
    "    x_all=pd.concat([const_x,ir_x,dummy_x],axis=1).iloc[:-(int(tw.split('-')[1].split('D')[0]))].copy()\n",
    "    y_train,y_test,x_train,x_test=train_test_split(y,x_all,test_size=92,shuffle=False)\n",
    "    \n",
    "    res = sm.OLS(y_train,x_train ).fit()\n",
    "    predict_y_test = res.predict(x_test)\n",
    "    RMSE= np.nan if test_size==1 else mean_squared_error(y_test,predict_y_test,squared=False)\n",
    "\n",
    "    df_y=pd.concat([y,res.predict(x_all)],axis=1)\n",
    "    df_y.columns=[\"Real\",\"Predict\"]\n",
    "    \n",
    "    df_y_test=pd.concat([y_test,predict_y_test],axis=1)\n",
    "    df_y_test.columns=[\"Real_test\",\"Predict_test\"] \n",
    "\n",
    "\n",
    "    if return_to==\"overview\":\n",
    "        return pd.DataFrame([\"{}_{}_WD_{}\".format(c,b,tw),\n",
    "                                res.params.index.tolist(),\n",
    "                                res.params.tolist(),\n",
    "                                int(sum(res.pvalues>0.05)),\n",
    "                                res.rsquared,\n",
    "                                res.f_pvalue,\n",
    "                                RMSE],\n",
    "                                index=[\"Y_feature\",\"X_features\",\"Coef\",\n",
    "                                       \"num_unappropriated_pvalue\",\"R_2\",\n",
    "                                       \"f_pvalue\",\"RMSE\"]).T\n",
    "    if return_to==\"detail\":\n",
    "        print(\"RMSE trước hiệu chỉnh (%) \",round(RMSE,2))\n",
    "        print(\"R2(%) \",round(res.rsquared*100,2))\n",
    "        print(pd.concat([y,x_all],axis=1).corr()[[y.name]])\n",
    "        print(res.summary())\n",
    "\n",
    "    if return_to==\"plot_reg\":\n",
    "        df_handled=handling_data_plot(df_y,tw,c=c,b=b,per=None)\n",
    "        fig=plot_reg(df_handled,tw,test_size,b=b,c=c,figsize=figsize,dpi=dpi)\n",
    "        if save_fig:\n",
    "            return fig\n",
    "        \n",
    "    if return_to==\"plot_mix\":\n",
    "        df_handled=handling_data_plot(df_y,tw,c=c,b=b,per=per)\n",
    "        fig=plot_mix(df_handled,tw,test_size,b,c,figsize=figsize,dpi=dpi)\n",
    "        if save_fig:\n",
    "            return fig\n",
    "        \n",
    "    if return_to==\"performance\":\n",
    "        df_handled=handling_data_plot(df_y,tw,c=c,b=b,per=per).iloc[-test_size:]/100\n",
    "        return performance_cal(df_handled).T.round(4)*100\n",
    "    \n",
    "    if return_to==\"backtest_mix\":\n",
    "        df_handled=handling_data_plot(df_y,tw,c=c,b=b,per=per).rename(columns={\"Real\":\"WD\",\"mix\":\"Estimate\"})/100\n",
    "        return df_handled\n",
    "    \n",
    "    if return_to==\"df_y\":\n",
    "        return df_y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' hàm define ở trên dùng ở đây '''\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "bucket = '30'\n",
    "\n",
    "ir_names= ['MSB_Medium_Term'] #[  'MSB_G2_Medium_Term', 'MSB_Long_Term']\n",
    "dummy_names=  ['ss_dummy','covid_dummy'] #\n",
    "# return_to = None                 # detail plot_reg plot_mix backtest_mix\n",
    "# check_ols_rb = run_OLS(b=b,c=c,tw=bucket,ir_names=ir_names,dummy_names=dummy_names,wd_reg=wd_reg,return_to=\"df_y\",test_size=test_size,save_fig=True,per=per)\n",
    "run_OLS(b=b,c=c,tw=bucket,ir_names=ir_names,dummy_names=dummy_names,wd_reg=wd_reg,return_to=\"detail\",test_size=test_size,save_fig=True,per=per)\n",
    "run_OLS(b=b,c=c,tw=bucket,ir_names=ir_names,dummy_names=dummy_names,wd_reg=wd_reg,return_to=\"plot_mix\",test_size=test_size,save_fig=True,per=per)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run loop all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "chạy loop các mô hình theo danh sách list_X_feature\n",
    "\"\"\"\n",
    "\n",
    "def run_OLS_loop(y_fea,list_X_feature,test_size):\n",
    "    global res_total\n",
    "    res_total=pd.DataFrame()\n",
    "    i=0\n",
    "    for x_fea in list_X_feature:\n",
    "        i+=1\n",
    "        print(i,end=\"\\r\")\n",
    "        res=run_OLS(x_fea.copy(), y_fea,data=df_reg.copy(),poly_degree=1,return_plot=False,test_size=test_size,return_summary=False)\n",
    "        res_total=res_total.append(res)\n",
    "    res_total.to_excel('total_models_{}.xlsx'.format(y_fea))\n",
    "    #res_total.to_excel('./ex_sign_PD_total_models_{}.xlsx'.format(y_fea), sheet_name='Sheet1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loc_bien(b,c,bk, wd_reg, all_var):\n",
    "    Y_var = wd_reg[[\"{}_{}_WD_{}\".format(c,b,bk)]]\n",
    "    df = pd.DataFrame()\n",
    "    for col in all_var.columns[1:].tolist():\n",
    "        corre = all_var[col].corr(Y_var[Y_var.columns[0]])\n",
    "        corr_df = pd.DataFrame(data = {Y_var.columns[0] :[corre]}, index = [col])\n",
    "        df = df.append(corr_df)\n",
    "    df = df[(df[Y_var.columns[0]].abs() > 0.2)]\n",
    "    df.reset_index(inplace = True)\n",
    "    all_x_var_list = df['index'].unique().tolist()\n",
    "    df_reg = pd.concat([Y_var,all_var[[i for i in all_var.columns.tolist() if i in all_x_var_list]]], axis = 1)\n",
    "    return df_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(df):\n",
    "    df['num_var'] = df['number_var']-1\n",
    "    n = df['num_var'].max()\n",
    "    for i in range(1,n):\n",
    "        df['X{}'.format(i)] = df['X_feature'].str.split(',').str[i].str.split(']').str[0].str.split(\"'\",n=2, expand = True)[1]\n",
    "        df['pvalue_X{}'.format(i)] = df['P_value'].str.split(',').str[i].str.split(']').str[0]\n",
    "        df['VIF_X{}'.format(i)] = df['VIF'].str.split(',').str[i].str.split(']').str[0]\n",
    "        df['coef_X{}'.format(i)] = df['Coef'].str.split(',').str[i].str.split(']').str[0]\n",
    "    df['pvalue_intercept'] = df['P_value'].str.split(',').str[0].str.split('[').str[1]\n",
    "    df['VIF_intercept'] = df['VIF'].str.split(',').str[0].str.split('[').str[1]\n",
    "    df['coef_intercept'] = df['Coef'].str.split(',').str[0].str.split('[').str[1]\n",
    "    df_final =df[['Y_feature'] + ['X{}'.format(i) for i in range(1,n)] \n",
    "                 + ['coef_intercept'] + ['coef_X{}'.format(i) for i in range(1,n)] +\n",
    "                 ['pvalue_intercept'] + ['pvalue_X{}'.format(i) for i in range(1,n)] \n",
    "                + ['VIF_X{}'.format(i) for i in range(1,n)]\n",
    "                + ['num_var','R_2','MAPE of all','Adj_R_2', 'VIF_intercept',\"Cooks's Distance Max\", \n",
    "                    '%Cooks Value Pass',\n",
    "                    'Durbin Watson', 'KS test', 'ADF test AIC', 'ADF test BIC',\n",
    "                    'White_test', 'MAPE of all']]\n",
    "    col_list = df_final.columns.tolist()\n",
    "    for i in col_list[6:]:\n",
    "        df_final[i] = df_final[i].astype('float64')\n",
    "    #template = filter_model(df_final)\n",
    "    df_final.to_excel('./final_template{}_{}_WD_{}.xlsx'.format(c,b,bk), sheet_name='Sheet1')\n",
    "    return df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "bk = '30-90'\n",
    "\n",
    "test_size = 30\n",
    "\n",
    "\n",
    "data_regression= loc_bien(b,c,bk,wd_reg,all_var)\n",
    "\n",
    "Y_variables=data_regression.columns[0]\n",
    "X_variables=data_regression.columns[1:]\n",
    "df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "data_core_matrix=data_regression[X_variables].corr()\n",
    "sign=(data_core_matrix.abs()<0.4).astype(int)\n",
    "list_X_feature=[[i] for i in X_variables]\n",
    "for n in range(2,len(X_variables)+1):\n",
    "    check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "    if len(check_n_1)==0:\n",
    "        break\n",
    "    list_X_feature_n=[]\n",
    "    for a in check_n_1:\n",
    "        list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            ###Chay model voi so bien <4 - tong so bien X\n",
    "        list_X_feature_n= [i for i in list_X_feature_n if len(i)<5] \n",
    "    list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "print(len(list_X_feature))\n",
    "for i in list_X_feature:\n",
    "    i += ['ss_dummy', 'covid_dummy' ]\n",
    "#list_X_feature\n",
    "\n",
    "#     \"\"\"chạy loop mô hình\"\"\"\n",
    "import threading\n",
    "thread = []\n",
    "for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "    thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "for j in thread:\n",
    "    j.start()\n",
    "    j.join() \n",
    "    #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{}.xlsx'.format(c,b,bk))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_X_feature_copy = list_X_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_test = list_X_feature[300:302]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GDP_lag_6m', 'GDP_per_change', 'ss_dummy', 'covid_dummy'],\n",
       " ['GDP_lag_6m', 'GDP_ma_3m', 'ss_dummy', 'covid_dummy']]"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list_X_feature_copy:\n",
    "    check = i\n",
    "    res =  [list(i) for j, i in groupby(check, lambda a: a.split('_')[0])]\n",
    "    for z in res:\n",
    "        if len(z) > 1:\n",
    "            list_X_feature_copy.remove(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9125"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_X_feature_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = [list(i) for j, i in groupby(list_test[0], lambda a: a.split('_')[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GDP_lag_6m', 'GDP_per_change'], ['ss_dummy'], ['covid_dummy']]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in res:\n",
    "    if len(i) > 1:\n",
    "        list_test.remove(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['GDP_lag_6m', 'GDP_per_change', 'ss_dummy', 'covid_dummy'],\n",
       " ['GDP_lag_6m', 'GDP_ma_3m', 'ss_dummy', 'covid_dummy']]"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['c'], ['o'], ['v'], ['i'], ['d'], ['_'], ['d'], ['u'], ['m', 'm'], ['y']]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_OLS(x_fea.copy(), y_fea,data=df_reg.copy(),poly_degree=1,return_plot=False,test_size=test_size,return_summary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "bk = '90-180'\n",
    "\n",
    "test_size = 30\n",
    "\n",
    "\n",
    "data_regression= loc_bien(b,c,bk,wd_reg,all_var)\n",
    "\n",
    "Y_variables=data_regression.columns[0]\n",
    "X_variables=data_regression.columns[1:]\n",
    "df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "data_core_matrix=data_regression[X_variables].corr()\n",
    "sign=(data_core_matrix.abs()<0.4).astype(int)\n",
    "list_X_feature=[[i] for i in X_variables]\n",
    "for n in range(2,len(X_variables)+1):\n",
    "    check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "    if len(check_n_1)==0:\n",
    "        break\n",
    "    list_X_feature_n=[]\n",
    "    for a in check_n_1:\n",
    "        list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            ###Chay model voi so bien <4 - tong so bien X\n",
    "        list_X_feature_n= [i for i in list_X_feature_n if len(i)<5] \n",
    "    list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "print(len(list_X_feature))\n",
    "for i in list_X_feature:\n",
    "    i += ['ss_dummy', 'covid_dummy' ]\n",
    "#list_X_feature\n",
    "\n",
    "#     \"\"\"chạy loop mô hình\"\"\"\n",
    "import threading\n",
    "thread = []\n",
    "for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "    thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "for j in thread:\n",
    "    j.start()\n",
    "    j.join() \n",
    "    #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{}.xlsx'.format(c,b,bk))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 43min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "bk = '180-365'\n",
    "\n",
    "test_size = 30\n",
    "\n",
    "\n",
    "data_regression= loc_bien(b,c,bk,wd_reg,all_var)\n",
    "\n",
    "Y_variables=data_regression.columns[0]\n",
    "X_variables=data_regression.columns[1:]\n",
    "df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "data_core_matrix=data_regression[X_variables].corr()\n",
    "sign=(data_core_matrix.abs()<0.5).astype(int)\n",
    "list_X_feature=[[i] for i in X_variables]\n",
    "for n in range(2,len(X_variables)+1):\n",
    "    check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "    if len(check_n_1)==0:\n",
    "        break\n",
    "    list_X_feature_n=[]\n",
    "    for a in check_n_1:\n",
    "        list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            ###Chay model voi so bien <4 - tong so bien X\n",
    "        list_X_feature_n= [i for i in list_X_feature_n if len(i)<5] \n",
    "    list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "print(len(list_X_feature))\n",
    "for i in list_X_feature:\n",
    "    i += ['ss_dummy', 'covid_dummy' ]\n",
    "#list_X_feature\n",
    "\n",
    "#     \"\"\"chạy loop mô hình\"\"\"\n",
    "import threading\n",
    "thread = []\n",
    "for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "    thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "for j in thread:\n",
    "    j.start()\n",
    "    j.join() \n",
    "    #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{}.xlsx'.format(c,b,bk))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 21min 34s\n",
      "Compiler : 258 ms\n",
      "Parser   : 1.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "bk = '365-730'\n",
    "\n",
    "test_size = 30\n",
    "\n",
    "\n",
    "data_regression= loc_bien(b,c,bk,wd_reg,all_var)\n",
    "\n",
    "Y_variables=data_regression.columns[0]\n",
    "X_variables=data_regression.columns[1:]\n",
    "df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "data_core_matrix=data_regression[X_variables].corr()\n",
    "sign=(data_core_matrix.abs()<0.6).astype(int)\n",
    "list_X_feature=[[i] for i in X_variables]\n",
    "for n in range(2,len(X_variables)+1):\n",
    "    check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "    if len(check_n_1)==0:\n",
    "        break\n",
    "    list_X_feature_n=[]\n",
    "    for a in check_n_1:\n",
    "        list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            ###Chay model voi so bien <4 - tong so bien X\n",
    "        list_X_feature_n= [i for i in list_X_feature_n if len(i)<5] \n",
    "    list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "print(len(list_X_feature))\n",
    "for i in list_X_feature:\n",
    "    i += ['ss_dummy', 'covid_dummy' ]\n",
    "#list_X_feature\n",
    "\n",
    "#     \"\"\"chạy loop mô hình\"\"\"\n",
    "import threading\n",
    "thread = []\n",
    "for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "    thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "for j in thread:\n",
    "    j.start()\n",
    "    j.join() \n",
    "    #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{}.xlsx'.format(c,b,bk))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 51 s\n",
      "Parser   : 106 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "tw = 730\n",
    "\n",
    "test_size = 30\n",
    "\n",
    "\n",
    "data_regression= loc_bien(b,c,tw,wd_reg,all_var)\n",
    "\n",
    "Y_variables=data_regression.columns[0]\n",
    "X_variables=data_regression.columns[1:]\n",
    "df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "data_core_matrix=data_regression[X_variables].corr()\n",
    "sign=(data_core_matrix.abs()<0.4).astype(int)\n",
    "list_X_feature=[[i] for i in X_variables]\n",
    "for n in range(2,len(X_variables)+1):\n",
    "    check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "    if len(check_n_1)==0:\n",
    "        break\n",
    "    list_X_feature_n=[]\n",
    "    for a in check_n_1:\n",
    "        list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "            ###Chay model voi so bien <4 - tong so bien X\n",
    "        list_X_feature_n= [i for i in list_X_feature_n if len(i)<4] \n",
    "    list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "print(len(list_X_feature))\n",
    "for i in list_X_feature:\n",
    "    i += ['ss_dummy', 'covid_dummy' ]\n",
    "#list_X_feature\n",
    "\n",
    "#     \"\"\"chạy loop mô hình\"\"\"\n",
    "import threading\n",
    "thread = []\n",
    "for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "    thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "for j in thread:\n",
    "    j.start()\n",
    "    j.join() \n",
    "    #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{:03}.xlsx'.format(c,b,tw))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.77 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "tw = 1095\n",
    "\n",
    "# test_size = 30\n",
    "\n",
    "\n",
    "# data_regression= loc_bien(b,c,tw,wd_reg,all_var)\n",
    "\n",
    "# Y_variables=data_regression.columns[0]\n",
    "# X_variables=data_regression.columns[1:]\n",
    "# df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "# data_core_matrix=data_regression[X_variables].corr()\n",
    "# sign=(data_core_matrix.abs()<0.4).astype(int)\n",
    "# list_X_feature=[[i] for i in X_variables]\n",
    "# for n in range(2,len(X_variables)+1):\n",
    "#     check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "#     if len(check_n_1)==0:\n",
    "#         break\n",
    "#     list_X_feature_n=[]\n",
    "#     for a in check_n_1:\n",
    "#         list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "#             ###Chay model voi so bien <4 - tong so bien X\n",
    "#         list_X_feature_n= [i for i in list_X_feature_n if len(i)<4] \n",
    "#     list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "# print(len(list_X_feature))\n",
    "# for i in list_X_feature:\n",
    "#     i += ['ss_dummy', 'covid_dummy' ]\n",
    "# #list_X_feature\n",
    "\n",
    "# #     \"\"\"chạy loop mô hình\"\"\"\n",
    "# import threading\n",
    "# thread = []\n",
    "# for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "#     thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "# for j in thread:\n",
    "#     j.start()\n",
    "#     j.join() \n",
    "#     #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{:03}.xlsx'.format(c,b,tw))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 328 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "tw = 1460\n",
    "\n",
    "# test_size = 30\n",
    "\n",
    "\n",
    "# data_regression= loc_bien(b,c,tw,wd_reg,all_var)\n",
    "\n",
    "# Y_variables=data_regression.columns[0]\n",
    "# X_variables=data_regression.columns[1:]\n",
    "# df_reg = pd.concat([data_regression,dummy_period_variables.iloc[:, -2:]], axis =1)\n",
    "# data_core_matrix=data_regression[X_variables].corr()\n",
    "# sign=(data_core_matrix.abs()<0.4).astype(int)\n",
    "# list_X_feature=[[i] for i in X_variables]\n",
    "# for n in range(2,len(X_variables)+1):\n",
    "#     check_n_1=[i for i in list_X_feature if len(i)==(n-1)]\n",
    "#     if len(check_n_1)==0:\n",
    "#         break\n",
    "#     list_X_feature_n=[]\n",
    "#     for a in check_n_1:\n",
    "#         list_X_feature_n+=[np.sort(a+[x]).tolist() for x in sign[sign[a].prod(1)==1].index]\n",
    "#             ###Chay model voi so bien <4 - tong so bien X\n",
    "#         list_X_feature_n= [i for i in list_X_feature_n if len(i)<4] \n",
    "#     list_X_feature+=pd.DataFrame(list_X_feature_n).drop_duplicates().values.tolist() \n",
    "# print(len(list_X_feature))\n",
    "# for i in list_X_feature:\n",
    "#     i += ['ss_dummy', 'covid_dummy' ]\n",
    "# #list_X_feature\n",
    "\n",
    "# #     \"\"\"chạy loop mô hình\"\"\"\n",
    "# import threading\n",
    "# thread = []\n",
    "# for i in [Y_variables]: #depend on the name of z variable in excel file\n",
    "#     thread.append(threading.Thread(target=run_OLS_loop, args=(i,list_X_feature,test_size)))\n",
    "\n",
    "# for j in thread:\n",
    "#     j.start()\n",
    "#     j.join() \n",
    "#     #np.seterr(invalid='ignore')\n",
    "\n",
    "res_total = pd.read_excel('./total_models_{}_{}_WD_{:03}.xlsx'.format(c,b,tw))\n",
    "res_total_final = write_model(res_total)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_var.to_excel(\"all_var_irrbb.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lọc model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def X_sign(list_x):\n",
    "#     res=[]\n",
    "#     IR_names=all_var.columns\n",
    "#     for i in list_x:\n",
    "#         if isinstance(i,(int,float)):\n",
    "#             res.append(np.sign(i))\n",
    "#         elif i ==\"const\":\n",
    "#             res.append(0)\n",
    "#         elif i in IR_names:\n",
    "#             res.append(-1)\n",
    "#         elif i in \"ss_dummy\":\n",
    "#             res.append(1)\n",
    "#         else: # covid dummy\n",
    "#             res.append(0)\n",
    "#     return res\n",
    "\n",
    "# def filter_true_model(model):\n",
    "#     l1=model.Coef.map(X_sign).tolist()\n",
    "#     l2=model.X_features.map(X_sign).tolist()\n",
    "#     res=[]\n",
    "#     for i in range(len(l1)):\n",
    "#         check=[(a*b) for a,b in zip(l1[i],l2[i])]\n",
    "#         res.append((-1 not in check))\n",
    "#     return res\n",
    "\n",
    "# def true_model(b,c):\n",
    "#     model=pd.read_pickle(\"Regression/check_model_102021_{}_{}.pickle\".format(c,b))\n",
    "#     res=model.loc[filter_true_model(model)].sort_values([\"RMSE\",\"R_2\"],ascending=[True,False])\n",
    "#     res.drop_duplicates(['R_2','RMSE'],inplace=True)\n",
    "#     res.to_excel(\"Regression/true_model_{}_{}.xlsx\".format(c,b))\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for b,c in [(\"RC\",\"VND\")]:\n",
    "#     true_model(b=b,c=c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_mix(b,c,tw,df,MB_Core_all=MB_Core_all):\n",
    "    df=df.copy()\n",
    "    df[\"WDss\"]=(df[\"WD\"]*df.index.isin(ss_day_t0)).replace(0,np.nan)\n",
    "    df[\"WDst\"]=(df[\"WD\"]*df.index.isin(st_msb )).replace(0,np.nan)\n",
    "    t0=MB_Core_all[[(c,b,\"sum_000\")]].reindex(df.index).values\n",
    "    df2=df*t0\n",
    "    df2[\"T0\"]=t0\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=\"RC\"\n",
    "c=\"VND\"\n",
    "tw=30\n",
    "\n",
    "ir_names= ['MSB_G1_Long_Term'] #[  'MSB_G2_Medium_Term', 'MSB_Long_Term']\n",
    "dummy_names=  [\"covid_dummy\",\"ss_dummy\"] #\n",
    "# return_to = None                 # detail plot_reg plot_mix backtest_mix\n",
    "run_OLS(b=b,c=c,tw=tw,ir_names=ir_names,dummy_names=dummy_names,wd_reg=wd_reg,return_to=\"backtest_mix\",test_size=test_size,save_fig=True,per=per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_data_plot(per,reg):\n",
    "    return pd.concat([per,reg[[i for i in reg.columns if i not in per.columns]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Backtest_Timeseries_mix(b,c,tw,df):\n",
    "    \n",
    "    uni,div_uni=(\"Millions\",1000000) if c==\"USD\" else (\"Billions\",1000000000)\n",
    "    df=df/div_uni\n",
    "    max_y_axis=df.drop([\"T0\",\"TW\",\"Contractual_WD\"],axis=1).max().max()*1.3\n",
    "    x = df.index\n",
    "\n",
    "    \n",
    "    # plot time count cif\n",
    "    fig, ax1 = plt.subplots(1,1, figsize=(18, 10),dpi=100)\n",
    "\n",
    "    ax1.set_title(\"BACKTEST RÚT TIỀN DANH MỤC {} {} TIME-WINDOW {} ngày\".format(b,c,tw))\n",
    "\n",
    "    ax1.grid(alpha=0.2)\n",
    "    \n",
    "    cols=[\"WD\",\"WDss\",\"WDst\",\"Normal\",\"Seasonal\",\"Stress\",\"mix_regression\"]\n",
    "    col_labels=[\"Giá trị rút tại tại {} ngày sau tại thời điểm T0\".format(tw),\n",
    "               \"Giá trị rút tại tại {} ngày sau tại thời điểm T0 là giai đoạn mùa vụ\".format(tw),\n",
    "                \"Giá trị rút tại tại {} ngày sau tại thời điểm T0 là giai đoạn căng thẳng\".format(tw),\n",
    "                \"Ước lượng percentile rút thông thường\",\"Ước lượng percentile rút mùa vụ\",\"Ước lượng percentile rút căng thẳng\",\n",
    "                \"Ước lượng hồi quy sau hiệu chỉnh\",\n",
    "               ]\n",
    "    Colors=[\"grey\",\"green\",\"orange\",\"brown\",\"blue\",\"olivedrab\",\"red\"]\n",
    "    \n",
    "    for co,la,color in zip(cols,col_labels,Colors):\n",
    "        ls,alp=(\"-\",0.7) if co in [\"WD\", \"WDss\",\"WDst\",\"mix_regression\"] else (\"--\",1)\n",
    "        li=1.5 if co==\"mix_regression\" else 1\n",
    "        try:\n",
    "            ax1.plot(x,gaussian_filter1d(df[co], sigma=1),label=la,color=color,ls=ls,alpha=alp,linewidth=li)\n",
    "\n",
    "        except:\n",
    "            print(\"lỗi \",co)\n",
    "            pass\n",
    "    ax1.fill_between(x, 0, gaussian_filter1d(df[\"Contractual_WD\"], sigma=1),label=\"Giá trị hợp đồng đáo hạn trong timewindow\",color=\"violet\", alpha=0.1)\n",
    "    ax1.fill_between(x, 0, gaussian_filter1d(df[\"WD\"], sigma=1), alpha=0.2)\n",
    "\n",
    "\n",
    "    #plot normal period\n",
    "    end_train_day_tw=end_train_day-pd.Timedelta(days=tw)\n",
    "    ax1.vlines(x=x[(x<=end_train_day_tw) & (x.isin(ss_day_t0)==False)][-365], ymin=0, ymax=max_y_axis,ls=\"--\")\n",
    "    ax1.vlines(x=x[(x<=end_train_day_tw) & (x.isin(ss_day_t0)==False)][-1], ymin=0, ymax=max_y_axis,ls=\"--\")\n",
    "    ax1.annotate(text=\"Normal Period\",xy=(x[x.isin(ss_day_t0)==False][-200],max_y_axis*0.8))\n",
    "    \n",
    "    ax1.legend(loc=\"upper left\",ncol=3)\n",
    "    ax1.set_ylim(0, max_y_axis)\n",
    "\n",
    "    ax1.set_ylabel(uni)\n",
    "\n",
    "    ax1.set_xlabel('Begin date')\n",
    "    dayloc = mdates.MonthLocator([3,6,9,12])\n",
    "    ax1.xaxis.set_major_locator(dayloc)\n",
    "    ax1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "    fig.autofmt_xdate()\n",
    "#     plt.grid(alpha=0.4)\n",
    "    plt.show()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_backtest_violation_reg(df,b,c,tw):\n",
    "    \n",
    "    df=df[df.index<=(end_train_day-pd.Timedelta(days=tw))].rename(columns={\"mix_regression\":\"Estimate\"}).copy()\n",
    "    uni,div_uni=(\"Millions\",1000000) if c==\"USD\" else (\"Billions\",1000000000)\n",
    "    list_fig=[]\n",
    "    list_condition=[\"All\"] if b==\"L\" else [\"Normal\",\"Seasonal\",\"All\"]\n",
    "    for condition in list_condition:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(22.5, 3),dpi=68)\n",
    "        if condition==\"Normal\":\n",
    "            df2=df[df.index.isin(ss_day_t0)==False].iloc[-365:].copy()\n",
    "        elif condition==\"Seasonal\":\n",
    "            df2=df[df.index.isin(ss_day_t0)].copy()\n",
    "        else:\n",
    "            df2 = df.copy()\n",
    "            \n",
    "        df2[\"number_vio\"]=(df2[\"WD\"]>df2[\"Estimate\"]).astype(int)\n",
    "        df2[\"amount_vio\"]=(df2[\"WD\"]-df2[\"Estimate\"])*df2[\"number_vio\"]\n",
    "        df2[\"per_amount_vio\"]=df2[\"amount_vio\"]/df2[\"T0\"]\n",
    "    #         global df2_month\n",
    "        df2_month=df2.groupby(pd.Grouper(freq='MS')).agg({\"number_vio\":\"sum\",\"amount_vio\":\"mean\",\"per_amount_vio\":[\"max\",\"mean\"]}).applymap(lambda x: x if x>0 else np.nan)\n",
    "        df2_month.columns=df2_month.columns.map(lambda x: x[0]+\"_\"+x[1])\n",
    "        x=df2_month.index\n",
    "\n",
    "        ax_1,ax_2 = axs[0],axs[1]\n",
    "        #count violation\n",
    "        ax_1.grid(alpha=0.4)\n",
    "        ax_1.bar(x,df2_month.number_vio_sum.fillna(0),width=15)\n",
    "        ax_1.set_ylabel('Số vi phạm')\n",
    "        ax_1.set_title(\"BACKTEST SỐ LẦN VI PHẠM ƯỚC LƯỢNG HỒI QUY DANH MỤC {} {} TIME-WINDOW {} NGÀY ({})\".format(b,c,tw,condition))\n",
    "        for i in df2_month.dropna().index:\n",
    "            ax_1.annotate(text=df2_month.loc[i,\"number_vio_sum\"].astype(int),xy=(i,df2_month.loc[i,\"number_vio_sum\"]),  va='center',xytext=(-3,7), textcoords='offset points')\n",
    "\n",
    "        dayloc = mdates.MonthLocator([3,6,9,12])\n",
    "        ax_1.xaxis.set_major_locator(dayloc)\n",
    "        ax_1.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        try:\n",
    "            ax_1.set_ylim(0, df2_month.number_vio_sum.max()*1.2)\n",
    "        except:\n",
    "            pass\n",
    "        ax_1.set_xlabel('Begin date')\n",
    "\n",
    "        # balance of violation\n",
    "        ax_2.set_title(\"BACKTEST MỨC ĐỘ VI PHẠM ƯỚC LƯỢNG HỒI QUY DANH MỤC {} {} TIME-WINDOW {} NGÀY ({})\".format(b,c,tw,condition))\n",
    "        ax_2.grid(alpha=0.4)\n",
    "        ax_2.fill_between(x, 0, df2_month['per_amount_vio_max'].fillna(0)*100, alpha=0.4,color=\"orange\",label=\"Tỷ lệ (%) vi phạm lớn nhất\")\n",
    "        ax_2.fill_between(x, 0, df2_month['per_amount_vio_mean'].fillna(0)*100, alpha=1,color=\"orange\",label=\"Tỷ lệ (%) vi phạm trung bình\")\n",
    "        ax_2.set_ylabel('%')\n",
    "        ax_2.set_xlabel('Begin date')\n",
    "\n",
    "        ax2_2=ax_2.twinx()\n",
    "        ax2_2.bar(x,df2_month[\"amount_vio_mean\"].fillna(0)/div_uni,width=15,label=\"Giá trị vi phạm trung bình\")\n",
    "        ax2_2.set_ylabel(uni)\n",
    "\n",
    "        ax_2.legend(loc=\"upper left\",ncol=2)\n",
    "        ax2_2.legend(loc=\"upper right\")\n",
    "\n",
    "        ax_2.xaxis.set_major_locator(dayloc)\n",
    "        ax_2.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))\n",
    "        try:\n",
    "            ax_2.set_ylim(0, df2_month['per_amount_vio_max'].max()*140)\n",
    "            ax2_2.set_ylim(0, df2_month['amount_vio_mean'].max()/div_uni*1.4)\n",
    "        except:\n",
    "            pass\n",
    "        fig.autofmt_xdate()\n",
    "        plt.show()\n",
    "        list_fig.append(fig)\n",
    "    return list_fig,list_condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backup toàn bộ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m''' phân loại số tài khoản theo mã sản phẩm '''\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcal_rate\u001b[39m(date,table,func\u001b[38;5;241m=\u001b[39m\u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mnansum):\n\u001b[0;32m      3\u001b[0m     df \u001b[38;5;241m=\u001b[39m table[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mACCTNO\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mgroupby([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTYPE\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mcount()\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m2\u001b[39m:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "''' phân loại số tài khoản theo mã sản phẩm '''\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df = table[[\"TYPE\",'ACCTNO']].groupby([\"TYPE\"]).count()\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data,method_mat=\"ALL_{}_{}\".format(0,30))\n",
    "        date_tw1=date+pd.Timedelta(\"{}D\".format(0)) # date+tw1\n",
    "        date_tw2=date+pd.Timedelta(\"{}D\".format(30)) # date+tw2\n",
    "        all_tw1=return_df_tw2(date_tw1,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw1\n",
    "        all_tw2=return_df_tw2(date_tw2,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw2\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket_sum = cal_rate(date,table=all_wit_bucket,func=np.nansum)\n",
    "        Result_day=pd.concat([Result_day,all_wit_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "\n",
    "Result\n",
    "# Result.to_excel(r'D:\\IRRBB 2022\\output_T10_2022\\backup\\30-90.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' phân loại số tài khoản dựa trên kì hạn hợp đồng '''\n",
    "## chạy classify dựa trên classify_term (kì hạn hợp đồng)\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df = table[[\"Classify_term\",'ACCTNO']].groupby([\"Classify_term\"]).count()\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date[:2]:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data,method_mat=\"ALL_{}_{}\".format(30,90))\n",
    "        date_tw1=date+pd.Timedelta(\"{}D\".format(30)) # date+tw1\n",
    "        date_tw2=date+pd.Timedelta(\"{}D\".format(90)) # date+tw2\n",
    "        all_tw1=return_df_tw2(date_tw1,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw1\n",
    "        all_tw2=return_df_tw2(date_tw2,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw2\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket_sum = cal_rate(date,table=all_wit_bucket,func=np.nansum)\n",
    "        Result_day=pd.concat([Result_day,all_wit_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "\n",
    "Result\n",
    "# Result.to_excel(r'D:\\IRRBB 2022\\output_T10_2022\\backup\\30-90.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tính số lượng account rút trước hạn '''\n",
    "\n",
    "def return_df_tw2(date,table=data,danhmuc=[None,None],method_mat=\"ALL_0_1\"):\n",
    "    tw1=int(method_mat.split(\"_\")[1])\n",
    "    tw2=int(method_mat.split(\"_\")[-1])\n",
    "    method = method_mat.split(\"_\")[0]\n",
    "    c_mat_1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\")))\\\n",
    "               if (\"ALL\" in method) else False)  \n",
    "    c_wit_cond1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\"))) if (\"wbetween\" in method) else False)\n",
    "    c_wit_1 = ((table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")) if (tw1 == 0) else table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")))\\\n",
    "               if (\"wbetween\" in method) else False)\n",
    "    c_wit_2 = ((((table.CHECK_TO_DATE )<(date+pd.Timedelta(str(tw2)+\"D\"))))  if (\"wbetween\" in method) else False) \n",
    "    c_wit_between = (c_wit_cond1 & c_wit_1 &  c_wit_2)\n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & ( c_mat_1 | c_wit_between) ].copy()\n",
    "\n",
    "\n",
    "def calculate_sum_balance(date,t,table=data,key=\"ALL\"):        \n",
    "    df = table[[\"CURTYP\",\"bank\",\"ACCTNO\"]].groupby([\"CURTYP\",\"bank\"]).count()\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    df[[\"KIND\",\"Bucket\"]]=[key,t]\n",
    "    df.set_index([\"KIND\",\"Bucket\"],append=True,inplace=True)\n",
    "    return df.T\n",
    "\n",
    "def Nan_to_tw(table,level=3):\n",
    "    table.fillna(0,inplace=True)\n",
    "    #for i in table.columns:\n",
    "        #if int(i[level].split('-')[1].split('D')[0])>0: table.loc[table.index[-(int(i[level].split('-')[1].split('D')[0])>0):],i]=np.nan\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "list_tw1=[0,30,90,180,365,730,1095,1460,1825]\n",
    "list_tw2=[30,90,180,365,730,1095,1460,1825,2190]\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(9):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data,method_mat=\"ALL_{}_{}\".format(list_tw1[i],list_tw2[i])) # trả về bảng có mat > date + tw2\n",
    "        all_mat_bucket_sum=calculate_sum_balance(date,t = '{}-{}'.format(list_tw1[i],list_tw2[i]),table=all_mat_bucket,key=\"ALL\") # tính tổng giá trị all_mat_bucket\n",
    "        Result_day=pd.concat([Result_day,all_mat_bucket_sum],axis=1)\n",
    "        date_tw1=date+pd.Timedelta(\"{}D\".format(list_tw1[i])) # date+tw1\n",
    "        date_tw2=date+pd.Timedelta(\"{}D\".format(list_tw2[i])) # date+tw2\n",
    "        all_tw1=return_df_tw2(date_tw1,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw1\n",
    "        all_tw2=return_df_tw2(date_tw2,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw2\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket_sum=calculate_sum_balance(date,t ='{}-{}'.format(list_tw1[i],list_tw2[i]),table=all_wit_bucket,key=\"PRE\") #tính bảng có account RTHall_mat_bucket        \n",
    "        Result_day=pd.concat([Result_day,all_wit_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "    \n",
    "Nan_to_tw(Result)\n",
    "Result=Result.sort_index(axis=1, level = [0,1,2], sort_remaining = False)\n",
    "BWex=modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"RC\"],1,\"BWex\",axis=1).add(modify_columns_name(Result.iloc[:,Result.columns.get_level_values(1)==\"LSB\"],1,\"BWex\",axis=1),fill_value=0)\n",
    "Result_acc=pd.concat([Result,BWex],axis=1).sort_index(axis=1, level = [0], sort_remaining = False)\n",
    "#export\n",
    "Result_acc.to_pickle(output_folder+r\"Result_acc.pickle\")\n",
    "Result_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' tính số lượng account rút trước hạn\n",
    "phân chia theo số ngày còn lại của hợp đồng '''\n",
    "# Tính số ngày còn lại của hợp đồng đối với những tk rút trước hạn\n",
    "def term_dleft(x):\n",
    "    if x <=30: x='0-1M'\n",
    "    elif x <=90: x='1-3M'\n",
    "    elif x <=180: x ='3-6M'\n",
    "    elif x <=365: x ='6M-1Y'\n",
    "    elif x <= 730: x ='1Y-2Y'\n",
    "    elif x <= 1095: x = '2-3Y'\n",
    "    else: x='>3Y'\n",
    "    return x\n",
    "\n",
    "def return_df_tw2(date,table=data,danhmuc=[None,None],method_mat=\"ALL_0_1\"):\n",
    "    # Tw1, Tw2 là hai giá trị chặn trong Bucket muốn xét\n",
    "    # Method = ALL => xác định balance có MAT > TW2, Method = wBetween => Xác định withdrawal between Tw1 và TW2\n",
    "    tw1=int(method_mat.split(\"_\")[1])\n",
    "    tw2=int(method_mat.split(\"_\")[-1])\n",
    "    method = method_mat.split(\"_\")[0]\n",
    "    c_mat_1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\")))\\\n",
    "               if (\"ALL\" in method) else False)  \n",
    "    #các điều kiện xác định account rút trước hạn (mat>tw2 & rút trước hạn trong bucket đang xét)\n",
    "    c_wit_cond1 = ((table.MAT_DATE>(date+pd.Timedelta(str(tw2)+\"D\"))) if (\"wbetween\" in method) else False)\n",
    "    c_wit_1 = ((table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")) if (tw1 == 0) else table.CHECK_TO_DATE>=(date+pd.Timedelta(str(tw1)+\"D\")))\\\n",
    "               if (\"wbetween\" in method) else False)\n",
    "    c_wit_2 = ((((table.CHECK_TO_DATE )<(date+pd.Timedelta(str(tw2)+\"D\"))))  if (\"wbetween\" in method) else False) \n",
    "    #c_wit_2 = (((table.CHECK_TO_DATE + pd.Timedelta(str(1)+\"D\"))<(date+pd.Timedelta(str(tw2)+\"D\"))) if (\"wbetween\" in method) else False)  \n",
    "    c_wit_between = (c_wit_cond1 & c_wit_1 &  c_wit_2)\n",
    "    \n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & ( c_mat_1 | c_wit_between) ].copy()\n",
    "\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df = table[[\"Dleft_term\",'ACCTNO']].groupby([\"Dleft_term\"]).count()\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "list_tw1=[30]\n",
    "list_tw2=[90]\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data,method_mat=\"ALL_{}_{}\".format(30,90))\n",
    "        date_tw1=date+pd.Timedelta(\"{}D\".format(30)) # date+tw1\n",
    "        date_tw2=date+pd.Timedelta(\"{}D\".format(90)) # date+tw2\n",
    "        all_tw1=return_df_tw2(date_tw1,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw1\n",
    "        all_tw2=return_df_tw2(date_tw2,table=data,method_mat=\"ALL_0_0\") # danh mục tồn tại tại ngày date + tw2\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket = all_mat_bucket[all_mat_bucket.ACCTNO.isin(all_tw1.ACCTNO)][~all_mat_bucket.ACCTNO.isin(all_tw2.ACCTNO)]\n",
    "        all_wit_bucket['Dleft'] = (all_wit_bucket.MAT_DATE - all_wit_bucket.CHECK_TO_DATE)// pd.Timedelta ('1D')\n",
    "        all_wit_bucket['Dleft_term'] = all_wit_bucket.Dleft.map(term_dleft)\n",
    "        all_wit_bucket_sum = cal_rate(date,table=all_wit_bucket,func=np.nansum)\n",
    "        Result_day=pd.concat([Result_day,all_wit_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "\n",
    "Result\n",
    "# Result.to_excel(r'D:\\IRRBB 2022\\output_T10_2022\\backup\\30-90.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' USD/theo mã sản phẩm ứng vốn '''\n",
    "'''\n",
    "CHẠY USD THEO LIST TK ỨNG VỐN \n",
    "'''\n",
    "# Lọc tài khoản ứng vốn\n",
    "# df = data[data.CURTYP == 'USD']\n",
    "# tk_ungvon = pd.read_excel (r'D:\\IRRBB 2022\\output_T10_2022\\TK ỨNG VỐN.xlsx')\n",
    "# df_ungvon = data[data.TYPE.isin(tk_ungvon.ACCTNO)]\n",
    "\n",
    "# Define hàm xác định tài khoản và tính toán\n",
    "def return_df_tw2(date,table=data):\n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & (table.MAT_DATE>=table.CHECK_TO_DATE) ].copy()\n",
    "\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df = table[['bank',\"TYPE\",'CURRENT_BALANCE']].groupby(['bank',\"TYPE\"]).agg(func)\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=df_ungvon)\n",
    "        all_mat_bucket_sum=cal_rate(date,table=all_mat_bucket) \n",
    "        Result_day=pd.concat([Result_day,all_mat_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "Result=Result.sort_index(axis=1, level = [0], sort_remaining = False)\n",
    "Result\n",
    "\n",
    "# Result.to_excel(r'D:\\IRRBB 2022\\output_T10_2022\\backup\\30-90.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' VND/ mã sản phẩm (nói chung) '''\n",
    "# Define hàm xác định tài khoản và tính toán\n",
    "def return_df_tw2(date,table=data):\n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) & (table.MAT_DATE>=table.CHECK_TO_DATE) ].copy()\n",
    "\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df = table[['bank',\"TYPE\",'CURRENT_BALANCE']].groupby(['bank',\"TYPE\"]).agg(func)\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(1):\n",
    "        print(date.date(),end=\"\\r\")\n",
    "        all_mat_bucket=return_df_tw2(date,table=data)\n",
    "        all_mat_bucket_sum=cal_rate(date,table=all_mat_bucket) \n",
    "        Result_day=pd.concat([Result_day,all_mat_bucket_sum],axis=1)\n",
    "        clear_output()\n",
    "    Result =Result.append(Result_day)\n",
    "Result=Result.sort_index(axis=1, level = [0], sort_remaining = False)\n",
    "Result\n",
    "\n",
    "# Result.to_excel(r'D:\\IRRBB 2022\\output_T10_2022\\backup\\30-90.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tính lãi suất huy động"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tạo cột current balance theo rate\n",
    "data['cbal_rate']=data['CURRENT_BALANCE'] *data['RATE']\n",
    "\n",
    "# Define các hàm cần thiết\n",
    "def return_df_tw2(date,table=data):\n",
    "    return table [(table.CHECK_FROM_DATE<=date) & (table.CHECK_TO_DATE>=date) &  (table.MAT_DATE >= table.CHECK_TO_DATE)  ].copy()\n",
    "\n",
    "def cal_rate(date,table,func=np.nansum):\n",
    "    df=table.groupby(['bank','CURTYP','Classify_term']).agg({'cbal_rate':'sum','CURRENT_BALANCE':'sum'})\\\n",
    "                    .eval('avg_rate = cbal_rate / CURRENT_BALANCE').loc[:,'avg_rate'].to_frame()\n",
    "    if df.columns.nlevels==2:\n",
    "        df=df.melt(ignore_index=False,col_level=1,var_name=[\"func\"],value_name=date).set_index(\"func\",append=True)\n",
    "    else:\n",
    "        df.columns=[date]\n",
    "    return df.T\n",
    "\n",
    "\n",
    "start_date=pd.Timestamp('2016-01-01')\n",
    "end_date=pd.Timestamp('2022-11-30')\n",
    "list_date=pd.date_range(start=start_date,end=end_date).tolist()\n",
    "Result=pd.DataFrame()\n",
    "for date in list_date:\n",
    "    Result_day=pd.DataFrame()\n",
    "    for i in range(4):\n",
    "        print(date.date(),list_tw1[i],list_tw2[i],end=\"\\r\")\n",
    "        all_bucket=return_df_tw2(date,table=data) \n",
    "        all_bucket_sum=cal_rate(date,table=all_bucket) \n",
    "        clear_output()\n",
    "    Result= Result.append(all_bucket_sum)\n",
    "# Result.to_pickle (r'D:\\IRRBB 2022\\Lãi suất huy động\\lshd.pickle')\n",
    "# Result.to_excel (r'D:\\IRRBB 2022\\Lãi suất huy động\\lshd.xlsx')\n",
    "Result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5 (tags/v3.10.5:f377153, Jun  6 2022, 16:14:13) [MSC v.1929 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "27f6fea6f47ae512550f0b8facdbd035a93e1dd89633f7bf2dd00a2502c71d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
